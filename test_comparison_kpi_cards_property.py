"""
Property-Based Test for KPI Comparison Cards
Feature: store-comparison, Property 4: æ ¸å¿ƒæŒ‡æ ‡å¯¹æ¯”å®Œæ•´æ€§
Validates: Requirements 2.2, 2.3

This test verifies that the create_kpi_comparison_cards function generates
complete comparison cards with all required data elements.
"""

import unittest
from hypothesis import given, strategies as st, settings
from hypothesis import assume
import pandas as pd
from dashboard_v2 import DashboardComponents


# Strategy for generating valid KPI data
def kpi_data_strategy():
    """Generate random but valid KPI data dictionaries"""
    return st.fixed_dictionaries({
        # SKUæ•°é‡æŒ‡æ ‡
        'æ€»SKUæ•°(å«è§„æ ¼)': st.integers(min_value=0, max_value=10000),
        'æ€»SKUæ•°(å»é‡å)': st.integers(min_value=0, max_value=10000),
        'å•è§„æ ¼SKUæ•°': st.integers(min_value=0, max_value=5000),
        'å¤šè§„æ ¼SKUæ€»æ•°': st.integers(min_value=0, max_value=5000),
        # åŠ¨é”€æŒ‡æ ‡
        'åŠ¨é”€SKUæ•°': st.integers(min_value=0, max_value=10000),
        'æ»é”€SKUæ•°': st.integers(min_value=0, max_value=10000),
        'åŠ¨é”€ç‡': st.floats(min_value=0.0, max_value=1.0, allow_nan=False, allow_infinity=False),
        'å”¯ä¸€å¤šè§„æ ¼å•†å“æ•°': st.integers(min_value=0, max_value=5000),
        # é”€å”®æŒ‡æ ‡
        'æ€»é”€å”®é¢(å»é‡å)': st.floats(min_value=0.0, max_value=10000000.0, allow_nan=False, allow_infinity=False),
        'é—¨åº—çˆ†å“æ•°': st.integers(min_value=0, max_value=1000),
        'çˆ†æ¬¾é›†ä¸­åº¦': st.floats(min_value=0.0, max_value=1.0, allow_nan=False, allow_infinity=False),
        'å¹³å‡SKUå•ä»·': st.floats(min_value=0.0, max_value=10000.0, allow_nan=False, allow_infinity=False),
        # ä»·æ ¼ä¸ä¿ƒé”€æŒ‡æ ‡
        'é«˜ä»·å€¼SKUå æ¯”': st.floats(min_value=0.0, max_value=1.0, allow_nan=False, allow_infinity=False),
        'é—¨åº—å¹³å‡æŠ˜æ‰£': st.floats(min_value=0.0, max_value=1.0, allow_nan=False, allow_infinity=False),
        'ä¿ƒé”€å¼ºåº¦': st.floats(min_value=0.0, max_value=1.0, allow_nan=False, allow_infinity=False),
        # æˆæœ¬ä¸æ¯›åˆ©æŒ‡æ ‡
        'æ€»æˆæœ¬é”€å”®é¢': st.floats(min_value=0.0, max_value=10000000.0, allow_nan=False, allow_infinity=False),
        'æ€»æ¯›åˆ©': st.floats(min_value=0.0, max_value=10000000.0, allow_nan=False, allow_infinity=False),
        'å¹³å‡æ¯›åˆ©ç‡': st.floats(min_value=0.0, max_value=1.0, allow_nan=False, allow_infinity=False),
        'é«˜æ¯›åˆ©å•†å“æ•°': st.integers(min_value=0, max_value=1000)
    })


class TestKPIComparisonCardsProperty(unittest.TestCase):
    """
    Property 4: æ ¸å¿ƒæŒ‡æ ‡å¯¹æ¯”å®Œæ•´æ€§
    
    For any valid own-store and competitor KPI data, the comparison cards
    should contain all required elements: own-store value, competitor value,
    difference value, and difference percentage.
    """
    
    @given(own_kpi=kpi_data_strategy(), competitor_kpi=kpi_data_strategy())
    @settings(max_examples=100, deadline=None)
    def test_kpi_comparison_cards_completeness(self, own_kpi, competitor_kpi):
        """
        **Feature: store-comparison, Property 4: æ ¸å¿ƒæŒ‡æ ‡å¯¹æ¯”å®Œæ•´æ€§**
        **Validates: Requirements 2.2, 2.3**
        
        Property: For any valid KPI data (own-store and competitor),
        the create_kpi_comparison_cards function should return a component
        that contains comparison cards with:
        1. Own-store values
        2. Competitor values
        3. Difference values
        4. Difference percentages
        """
        # Generate comparison cards
        result = DashboardComponents.create_kpi_comparison_cards(own_kpi, competitor_kpi)
        
        # Verify result is not None
        self.assertIsNotNone(result, "Result should not be None")
        
        # Verify result has children (the cards)
        self.assertTrue(hasattr(result, 'children'), "Result should have children attribute")
        cards = result.children
        self.assertIsInstance(cards, list, "Cards should be a list")
        
        # Verify we have cards (at least some metrics should generate cards)
        # Note: Some metrics might be skipped if both own and competitor don't have them
        # But with our generated data, we should always have cards
        self.assertGreater(len(cards), 0, "Should generate at least one comparison card")
        
        # For each card, verify it contains the required elements
        for card_col in cards:
            # Each card is wrapped in a dbc.Col
            self.assertTrue(hasattr(card_col, 'children'), "Card column should have children")
            card = card_col.children
            
            # Verify card has a body
            self.assertTrue(hasattr(card, 'children'), "Card should have children")
            card_body_list = card.children
            self.assertIsInstance(card_body_list, list, "Card children should be a list")
            self.assertGreater(len(card_body_list), 0, "Card should have at least one child (CardBody)")
            
            # Get the card body
            card_body = card_body_list[0]
            self.assertTrue(hasattr(card_body, 'children'), "CardBody should have children")
            
            # The card body contains two main divs:
            # 1. Icon and title div
            # 2. Values div (own-store, competitor, difference)
            body_children = card_body.children
            self.assertIsInstance(body_children, list, "CardBody children should be a list")
            self.assertGreaterEqual(len(body_children), 2, "CardBody should have at least 2 children")
            
            # Get the values div (second child)
            values_div = body_children[1]
            self.assertTrue(hasattr(values_div, 'children'), "Values div should have children")
            
            values_children = values_div.children
            self.assertIsInstance(values_children, list, "Values children should be a list")
            
            # Verify we have at least 4 elements:
            # 1. Own-store div
            # 2. Competitor div
            # 3. Horizontal rule
            # 4. Difference div
            self.assertGreaterEqual(len(values_children), 4, 
                                   "Values div should have at least 4 children (own, competitor, hr, difference)")
            
            # Verify own-store value exists
            own_div = values_children[0]
            self.assertTrue(hasattr(own_div, 'children'), "Own-store div should have children")
            own_children = own_div.children
            self.assertIsInstance(own_children, list, "Own-store children should be a list")
            self.assertGreaterEqual(len(own_children), 2, "Own-store div should have label and value")
            
            # Verify competitor value exists
            comp_div = values_children[1]
            self.assertTrue(hasattr(comp_div, 'children'), "Competitor div should have children")
            comp_children = comp_div.children
            self.assertIsInstance(comp_children, list, "Competitor children should be a list")
            self.assertGreaterEqual(len(comp_children), 2, "Competitor div should have label and value")
            
            # Verify difference div exists
            diff_div = values_children[3]
            self.assertTrue(hasattr(diff_div, 'children'), "Difference div should have children")
            diff_children = diff_div.children
            self.assertIsInstance(diff_children, list, "Difference children should be a list")
            self.assertGreaterEqual(len(diff_children), 2, 
                                   "Difference div should have arrow and text (with percentage)")
    
    @given(own_kpi=kpi_data_strategy(), competitor_kpi=kpi_data_strategy())
    @settings(max_examples=100, deadline=None)
    def test_kpi_comparison_cards_count(self, own_kpi, competitor_kpi):
        """
        Property: For any valid KPI data, the number of comparison cards
        should match the number of metrics that exist in either own-store
        or competitor data.
        """
        # Generate comparison cards
        result = DashboardComponents.create_kpi_comparison_cards(own_kpi, competitor_kpi)
        
        # Count expected cards (metrics that exist in either dataset)
        expected_metrics = [
            'æ€»SKUæ•°(å«è§„æ ¼)', 'æ€»SKUæ•°(å»é‡å)', 'å•è§„æ ¼SKUæ•°', 'å¤šè§„æ ¼SKUæ€»æ•°',
            'åŠ¨é”€SKUæ•°', 'æ»é”€SKUæ•°', 'åŠ¨é”€ç‡', 'å”¯ä¸€å¤šè§„æ ¼å•†å“æ•°',
            'æ€»é”€å”®é¢(å»é‡å)', 'é—¨åº—çˆ†å“æ•°', 'çˆ†æ¬¾é›†ä¸­åº¦', 'å¹³å‡SKUå•ä»·',
            'é«˜ä»·å€¼SKUå æ¯”', 'é—¨åº—å¹³å‡æŠ˜æ‰£', 'ä¿ƒé”€å¼ºåº¦',
            'æ€»æˆæœ¬é”€å”®é¢', 'æ€»æ¯›åˆ©', 'å¹³å‡æ¯›åˆ©ç‡', 'é«˜æ¯›åˆ©å•†å“æ•°'
        ]
        
        expected_count = 0
        for metric in expected_metrics:
            if metric in own_kpi or metric in competitor_kpi:
                expected_count += 1
        
        # Get actual card count
        cards = result.children
        actual_count = len(cards)
        
        # Verify counts match
        self.assertEqual(actual_count, expected_count,
                        f"Should generate {expected_count} cards for available metrics, got {actual_count}")
    
    @given(own_kpi=kpi_data_strategy(), competitor_kpi=kpi_data_strategy())
    @settings(max_examples=100, deadline=None)
    def test_kpi_comparison_difference_calculation(self, own_kpi, competitor_kpi):
        """
        Property: For any valid KPI data, the difference values and percentages
        should be correctly calculated as (own - competitor) and ((own - competitor) / competitor * 100).
        """
        # Generate comparison cards
        result = DashboardComponents.create_kpi_comparison_cards(own_kpi, competitor_kpi)
        
        # We can't easily extract and verify the exact difference values from the rendered components
        # without parsing the HTML/text, but we can verify that the function doesn't crash
        # and produces valid output structure
        
        # Verify result structure is valid
        self.assertIsNotNone(result)
        cards = result.children
        self.assertIsInstance(cards, list)
        
        # For each metric, manually verify the calculation logic would be correct
        for key in own_kpi.keys():
            if key in competitor_kpi:
                own_val = own_kpi[key]
                comp_val = competitor_kpi[key]
                
                # Calculate expected difference
                expected_diff = own_val - comp_val
                
                # Calculate expected percentage
                if comp_val != 0:
                    expected_pct = (expected_diff / comp_val) * 100
                else:
                    expected_pct = 0
                
                # Verify calculations are valid numbers
                self.assertIsInstance(expected_diff, (int, float))
                self.assertIsInstance(expected_pct, (int, float))
                self.assertFalse(pd.isna(expected_diff), "Difference should not be NaN")
                self.assertFalse(pd.isna(expected_pct), "Percentage should not be NaN")


def run_property_tests():
    """Run property-based tests"""
    loader = unittest.TestLoader()
    suite = loader.loadTestsFromTestCase(TestKPIComparisonCardsProperty)
    
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    print("\n" + "="*70)
    print("ğŸ“Š Property-Based Test Summary")
    print("="*70)
    print(f"âœ… Tests Run: {result.testsRun}")
    print(f"âœ… Passed: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"âŒ Failed: {len(result.failures)}")
    print(f"ğŸ’¥ Errors: {len(result.errors)}")
    
    if result.wasSuccessful():
        print("\nğŸ‰ All property-based tests passed!")
        print("\nğŸ“ˆ Property Validated:")
        print("   âœ… Property 4: æ ¸å¿ƒæŒ‡æ ‡å¯¹æ¯”å®Œæ•´æ€§")
        print("   âœ… Requirements 2.2, 2.3")
        return 0
    else:
        print("\nâš ï¸  Some property tests failed")
        if result.failures:
            print("\nFailures:")
            for test, traceback in result.failures:
                print(f"  - {test}: {traceback}")
        if result.errors:
            print("\nErrors:")
            for test, traceback in result.errors:
                print(f"  - {test}: {traceback}")
        return 1


if __name__ == '__main__':
    import sys
    sys.exit(run_property_tests())
