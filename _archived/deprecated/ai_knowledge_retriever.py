"""
AIä¸šåŠ¡çŸ¥è¯†å‘é‡æ£€ç´¢æ¨¡å—
Phase 1: å¢å¼ºç°æœ‰æ–¹æ¡ˆ - å‘é‡æ£€ç´¢é›†æˆ

åŠŸèƒ½:
1. å°†2500è¡Œä¸šåŠ¡çŸ¥è¯†åº“å‘é‡åŒ–
2. æ ¹æ®ç”¨æˆ·é—®é¢˜è‡ªåŠ¨æ£€ç´¢ç›¸å…³çŸ¥è¯†
3. æ™ºèƒ½æ³¨å…¥åˆ°æç¤ºè¯ä¸­

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024å¹´10æœˆ27æ—¥
ç‰ˆæœ¬: v1.0
"""

import os
import pickle
from typing import List, Dict, Optional
from pathlib import Path

# å‘é‡æ£€ç´¢ç›¸å…³ - å»¶è¿Ÿå¯¼å…¥é¿å…å¯åŠ¨é˜»å¡
VECTOR_SEARCH_AVAILABLE = False
_langchain_modules = None

def _lazy_load_langchain():
    """å»¶è¿ŸåŠ è½½langchainæ¨¡å—"""
    global VECTOR_SEARCH_AVAILABLE, _langchain_modules
    if _langchain_modules is not None:
        return _langchain_modules
    
    try:
        from langchain_text_splitters import RecursiveCharacterTextSplitter
        from langchain_community.vectorstores import FAISS
        from langchain_community.embeddings import HuggingFaceEmbeddings
        
        _langchain_modules = {
            'RecursiveCharacterTextSplitter': RecursiveCharacterTextSplitter,
            'FAISS': FAISS,
            'HuggingFaceEmbeddings': HuggingFaceEmbeddings
        }
        VECTOR_SEARCH_AVAILABLE = True
        print("âœ… å‘é‡æ£€ç´¢æ¨¡å—å·²åŠ è½½")
        return _langchain_modules
    except ImportError as e:
        VECTOR_SEARCH_AVAILABLE = False
        print(f"âš ï¸ å‘é‡æ£€ç´¢ä¾èµ–æœªå®‰è£…,ä½¿ç”¨åŸºç¡€æ¨¡å¼: {e}")
        return None


class BusinessKnowledgeRetriever:
    """ä¸šåŠ¡çŸ¥è¯†å‘é‡æ£€ç´¢å™¨"""
    
    def __init__(self, cache_dir: str = "./cache"):
        """
        åˆå§‹åŒ–æ£€ç´¢å™¨
        
        Args:
            cache_dir: å‘é‡åº“ç¼“å­˜ç›®å½•
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
        self.vectorstore = None
        self.embeddings = None
        
        if VECTOR_SEARCH_AVAILABLE:
            self._init_embeddings()
            self._load_or_build_vectorstore()
        else:
            print("âš ï¸ å‘é‡æ£€ç´¢ä¸å¯ç”¨,å°†ä½¿ç”¨å…¨é‡ä¸šåŠ¡çŸ¥è¯†")
    
    def _init_embeddings(self):
        """åˆå§‹åŒ–ä¸­æ–‡å‘é‡æ¨¡å‹"""
        print("ğŸ”§ åˆå§‹åŒ–ä¸­æ–‡å‘é‡æ¨¡å‹...")
        
        # ä½¿ç”¨è½»é‡çº§ä¸­æ–‡å‘é‡æ¨¡å‹
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        print("âœ… å‘é‡æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def _load_or_build_vectorstore(self):
        """åŠ è½½æˆ–æ„å»ºå‘é‡åº“"""
        vectorstore_path = self.cache_dir / "business_knowledge_vectorstore"
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨
        if vectorstore_path.exists():
            try:
                print("ğŸ“¦ åŠ è½½å·²ç¼“å­˜çš„å‘é‡åº“...")
                self.vectorstore = FAISS.load_local(
                    str(vectorstore_path),
                    self.embeddings,
                    allow_dangerous_deserialization=True
                )
                print("âœ… å‘é‡åº“åŠ è½½æˆåŠŸ")
                return
            except Exception as e:
                print(f"âš ï¸ åŠ è½½å‘é‡åº“å¤±è´¥: {e}")
                print("ğŸ”„ é‡æ–°æ„å»ºå‘é‡åº“...")
        
        # æ„å»ºæ–°çš„å‘é‡åº“
        self._build_vectorstore()
        
        # ä¿å­˜å‘é‡åº“
        if self.vectorstore:
            try:
                self.vectorstore.save_local(str(vectorstore_path))
                print(f"ğŸ’¾ å‘é‡åº“å·²ä¿å­˜åˆ°: {vectorstore_path}")
            except Exception as e:
                print(f"âš ï¸ ä¿å­˜å‘é‡åº“å¤±è´¥: {e}")
    
    def _build_vectorstore(self):
        """æ„å»ºå‘é‡åº“"""
        print("ğŸ—ï¸ æ„å»ºä¸šåŠ¡çŸ¥è¯†å‘é‡åº“...")
        
        # åŠ è½½ä¸šåŠ¡çŸ¥è¯†
        from ai_business_context import BUSINESS_CONTEXT
        
        # æ–‡æœ¬åˆ†å—
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,  # æ¯å—500å­—ç¬¦
            chunk_overlap=50,  # é‡å 50å­—ç¬¦
            separators=["\n\n", "\n", "ã€‚", "!", "?", ";", "ï¼›", "!", "?", ",", "ã€", " "],
            keep_separator=True
        )
        
        chunks = text_splitter.split_text(BUSINESS_CONTEXT)
        print(f"ğŸ“„ ä¸šåŠ¡çŸ¥è¯†å·²åˆ†å—: {len(chunks)} ä¸ªç‰‡æ®µ")
        
        # æ„å»ºå‘é‡åº“
        self.vectorstore = FAISS.from_texts(
            texts=chunks,
            embedding=self.embeddings,
            metadatas=[{"source": f"chunk_{i}"} for i in range(len(chunks))]
        )
        print("âœ… å‘é‡åº“æ„å»ºå®Œæˆ")
    
    def retrieve_relevant_knowledge(
        self, 
        query: str, 
        top_k: int = 5,
        score_threshold: float = 0.3
    ) -> List[str]:
        """
        æ£€ç´¢ç›¸å…³ä¸šåŠ¡çŸ¥è¯†
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            top_k: è¿”å›æœ€ç›¸å…³çš„Kä¸ªç‰‡æ®µ
            score_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼(0-1)
        
        Returns:
            ç›¸å…³çŸ¥è¯†ç‰‡æ®µåˆ—è¡¨
        """
        if not VECTOR_SEARCH_AVAILABLE or not self.vectorstore:
            # é™çº§åˆ°å…¨é‡çŸ¥è¯†
            from ai_business_context import BUSINESS_CONTEXT
            return [BUSINESS_CONTEXT[:3000]]  # è¿”å›å‰3000å­—ç¬¦
        
        try:
            # ç›¸ä¼¼åº¦æœç´¢
            docs_with_scores = self.vectorstore.similarity_search_with_score(
                query, 
                k=top_k
            )
            
            # è¿‡æ»¤ä½ç›¸å…³åº¦ç»“æœ
            relevant_docs = [
                doc.page_content 
                for doc, score in docs_with_scores 
                if score < (1 - score_threshold)  # FAISSè·ç¦»è¶Šå°è¶Šç›¸ä¼¼
            ]
            
            if not relevant_docs:
                print(f"âš ï¸ æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†(é˜ˆå€¼={score_threshold}),ä½¿ç”¨é»˜è®¤çŸ¥è¯†")
                from ai_business_context import BUSINESS_CONTEXT
                return [BUSINESS_CONTEXT[:3000]]
            
            print(f"âœ… æ£€ç´¢åˆ° {len(relevant_docs)} ä¸ªç›¸å…³çŸ¥è¯†ç‰‡æ®µ")
            return relevant_docs
            
        except Exception as e:
            print(f"âŒ å‘é‡æ£€ç´¢å¤±è´¥: {e}")
            # é™çº§åˆ°å…¨é‡çŸ¥è¯†
            from ai_business_context import BUSINESS_CONTEXT
            return [BUSINESS_CONTEXT[:3000]]
    
    def get_contextual_knowledge(
        self,
        query: str,
        analysis_type: Optional[str] = None
    ) -> str:
        """
        è·å–ä¸Šä¸‹æ–‡ç›¸å…³çš„ä¸šåŠ¡çŸ¥è¯†
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢æˆ–åˆ†æä»»åŠ¡
            analysis_type: åˆ†æç±»å‹(å¦‚"å¥åº·åº¦è¯Šæ–­"ã€"å•†å“è§’è‰²è¯†åˆ«"ç­‰)
        
        Returns:
            ç»„åˆåçš„ä¸šåŠ¡çŸ¥è¯†æ–‡æœ¬
        """
        # æ„å»ºå¢å¼ºæŸ¥è¯¢
        enhanced_query = query
        if analysis_type:
            enhanced_query = f"{analysis_type}: {query}"
        
        # æ£€ç´¢ç›¸å…³çŸ¥è¯†
        relevant_chunks = self.retrieve_relevant_knowledge(
            enhanced_query, 
            top_k=5,
            score_threshold=0.3
        )
        
        # ç»„åˆçŸ¥è¯†ç‰‡æ®µ
        combined_knowledge = "\n\n---\n\n".join(relevant_chunks)
        
        return combined_knowledge
    
    def rebuild_vectorstore(self):
        """å¼ºåˆ¶é‡å»ºå‘é‡åº“(å½“ä¸šåŠ¡çŸ¥è¯†æ›´æ–°æ—¶è°ƒç”¨)"""
        print("ğŸ”„ å¼ºåˆ¶é‡å»ºå‘é‡åº“...")
        
        # åˆ é™¤æ—§ç¼“å­˜
        vectorstore_path = self.cache_dir / "business_knowledge_vectorstore"
        if vectorstore_path.exists():
            import shutil
            shutil.rmtree(vectorstore_path)
            print("ğŸ—‘ï¸ å·²åˆ é™¤æ—§å‘é‡åº“")
        
        # é‡æ–°æ„å»º
        if VECTOR_SEARCH_AVAILABLE:
            self._build_vectorstore()
            
            # ä¿å­˜æ–°å‘é‡åº“
            if self.vectorstore:
                self.vectorstore.save_local(str(vectorstore_path))
                print("âœ… æ–°å‘é‡åº“å·²æ„å»ºå¹¶ä¿å­˜")
        else:
            print("âš ï¸ å‘é‡æ£€ç´¢ä¸å¯ç”¨")


# å…¨å±€å•ä¾‹
_retriever_instance = None

def get_knowledge_retriever() -> BusinessKnowledgeRetriever:
    """è·å–ä¸šåŠ¡çŸ¥è¯†æ£€ç´¢å™¨å•ä¾‹"""
    global _retriever_instance
    if _retriever_instance is None:
        _retriever_instance = BusinessKnowledgeRetriever()
    return _retriever_instance


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯•ä¸šåŠ¡çŸ¥è¯†å‘é‡æ£€ç´¢")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    retriever = get_knowledge_retriever()
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "ä»€ä¹ˆæ˜¯æµé‡å“?å¦‚ä½•å®šä»·?",
        "åŠ¨é”€ç‡ä½äº60%æ€ä¹ˆåŠ?",
        "å¦‚ä½•è®¡ç®—ä¿ƒé”€å¼ºåº¦?",
        "å•†å“æˆæœ¬å æ¯”è¶…è¿‡70%æ˜¯å¦å¥åº·?",
        "çˆ†å“é›†ä¸­åº¦è¿‡é«˜æœ‰ä»€ä¹ˆé£é™©?"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ“ æµ‹è¯•æŸ¥è¯¢ {i}: {query}")
        print(f"{'='*60}")
        
        knowledge = retriever.get_contextual_knowledge(query)
        print(f"\næ£€ç´¢ç»“æœ ({len(knowledge)} å­—ç¬¦):")
        print("-" * 60)
        print(knowledge[:500] + "..." if len(knowledge) > 500 else knowledge)
        print("-" * 60)
    
    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆ!")
    print("=" * 60)
