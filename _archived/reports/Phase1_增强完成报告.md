# Phase 1: å¢å¼ºç°æœ‰æ–¹æ¡ˆ - å®ŒæˆæŠ¥å‘Š

## ğŸ“‹ é¡¹ç›®ç›®æ ‡
**åŸå§‹éœ€æ±‚**: "ç›®å‰å¸‚é¢ä¸Š,æœ‰è¾…åŠ©å¤§æ¨¡å‹æå‡çš„æ•°æ®åˆ†æçš„æ’ä»¶æˆ–è¯­è¨€?ä¸»è¦ç›®çš„æ˜¯è®©å¤§æ¨¡å‹åœ¨åˆ†ææ•°æ®çš„æ—¶å€™æ›´ä¸“ä¸š"

**é€‰æ‹©æ–¹æ¡ˆ**: Phase 1 - å‘é‡æ£€ç´¢é›†æˆ(åŸºäºLangChain + FAISS)

---

## âœ… å·²å®Œæˆå·¥ä½œ

### 1. ç¯å¢ƒé…ç½®ä¸ä¾èµ–å®‰è£…
**å®‰è£…åŒ…** (å·²æˆåŠŸå®‰è£…åˆ°`.venv`):
```
faiss-cpu==1.12.0            # Facebook AIç›¸ä¼¼åº¦æœç´¢
sentence-transformers==5.1.2  # HuggingFaceå¥å­åµŒå…¥
langchain==1.0.2              # æ ¸å¿ƒæ¡†æ¶
langchain-community           # ç¤¾åŒºæ‰©å±•
langchain-text-splitters      # æ–‡æœ¬åˆ†å‰²å™¨
torch==2.9.0                  # PyTorch (109.3 MB)
transformers==4.57.1          # HuggingFace Transformers
```

**å®‰è£…éªŒè¯**:
```powershell
PS> .\.venv\Scripts\pip.exe list | Select-String "faiss|sentence|langchain|torch"
âœ… æ‰€æœ‰ä¾èµ–å·²æˆåŠŸå®‰è£…
```

---

### 2. æ ¸å¿ƒæ¨¡å—å¼€å‘

#### ğŸ“¦ ai_knowledge_retriever.py (æ–°å»º - 270è¡Œ)

**æ ¸å¿ƒæ¶æ„**:
```python
class BusinessKnowledgeRetriever:
    """ä¸šåŠ¡çŸ¥è¯†å‘é‡æ£€ç´¢å™¨"""
    
    def __init__(self, cache_dir="./cache"):
        # åµŒå…¥æ¨¡å‹: paraphrase-multilingual-MiniLM-L12-v2 (ä¸­æ–‡å‹å¥½)
        self.embeddings = HuggingFaceEmbeddings(...)
        
        # FAISSå‘é‡åº“ (æ”¯æŒç¼“å­˜)
        self.vectorstore = FAISS.from_documents(...)
    
    def retrieve_relevant_knowledge(self, query: str, top_k=5) -> List[str]:
        """æ£€ç´¢æœ€ç›¸å…³çš„çŸ¥è¯†ç‰‡æ®µ"""
        docs = self.vectorstore.similarity_search_with_score(query, k=top_k)
        return [doc.page_content for doc, score in docs if score < 1.0]
    
    def get_contextual_knowledge(self, query: str, analysis_type: str) -> str:
        """ä¸»API: æ ¹æ®æŸ¥è¯¢å’Œåˆ†æç±»å‹è¿”å›ä¸Šä¸‹æ–‡çŸ¥è¯†"""
        # è‡ªåŠ¨æ„å»ºå®Œæ•´æŸ¥è¯¢: query + analysis_type
        # è¿”å›å‰5ä¸ªæœ€ç›¸å…³ç‰‡æ®µ (~2500å­—ç¬¦)
```

**å…³é”®ç‰¹æ€§**:
- âœ… **æ™ºèƒ½æ–‡æœ¬åˆ†å‰²**: RecursiveCharacterTextSplitter (500å­—ç¬¦/å—, 50å­—ç¬¦é‡å )
- âœ… **ç¼“å­˜æœºåˆ¶**: é¦–æ¬¡æ„å»ºåä¿å­˜åˆ°`./cache/business_knowledge_vectorstore`
- âœ… **é™çº§æ¨¡å¼**: ä¾èµ–ç¼ºå¤±æ—¶è‡ªåŠ¨é€€å›å…¨é‡çŸ¥è¯†åº“
- âœ… **è¯„åˆ†è¿‡æ»¤**: ä»…è¿”å›ç›¸ä¼¼åº¦åˆ†æ•°<1.0çš„é«˜è´¨é‡åŒ¹é…

**åµŒå…¥æ¨¡å‹é€‰æ‹©**:
```python
model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
# ç‰¹ç‚¹: 
# - å¤šè¯­è¨€æ”¯æŒ(ä¸­æ–‡+è‹±æ–‡)
# - è½»é‡çº§(~420MB, é¦–æ¬¡ä¸‹è½½åç¼“å­˜)
# - 384ç»´å‘é‡, å¹³è¡¡ç²¾åº¦ä¸æ€§èƒ½
```

---

#### ğŸ”§ ai_analyzer.py (å¢å¼ºé›†æˆ)

**æ–°å¢å¯¼å…¥**:
```python
from ai_knowledge_retriever import get_knowledge_retriever
VECTOR_RETRIEVAL_ENABLED = True  # å…¨å±€å¼€å…³
```

**å¢å¼ºåˆå§‹åŒ–**:
```python
class AIAnalyzer:
    def __init__(self):
        # ... åŸæœ‰ä»£ç  ...
        
        # æ–°å¢: å‘é‡æ£€ç´¢å™¨
        self.knowledge_retriever = None
        if VECTOR_RETRIEVAL_ENABLED:
            try:
                self.knowledge_retriever = get_knowledge_retriever()
                print("âœ… å‘é‡æ£€ç´¢å™¨å·²åŠ è½½")
            except Exception as e:
                print(f"âš ï¸ å‘é‡æ£€ç´¢å™¨åŠ è½½å¤±è´¥,ä½¿ç”¨åŸºç¡€æ¨¡å¼: {e}")
```

**æ™ºèƒ½æŸ¥è¯¢æ„å»º** (æ–°å‡½æ•°):
```python
def _build_retrieval_query(self, kpi_data: Dict, category_data: list, meta_data: Dict) -> str:
    """
    æ ¹æ®æ•°æ®ç‰¹å¾æ„å»ºæ™ºèƒ½æ£€ç´¢æŸ¥è¯¢
    
    ç­–ç•¥:
    1. åŠ¨é”€ç‡ < 60% â†’ "åŠ¨é”€ç‡ä½ å¦‚ä½•ä¼˜åŒ–å•†å“ç»“æ„"
    2. æ»é”€å æ¯” > 20% â†’ "æ»é”€å æ¯”è¿‡é«˜ æ¸…ç†åº“å­˜"
    3. æŠ˜æ‰£æ·±åº¦ > -20% â†’ "æŠ˜æ‰£è¿‡æ·± æˆæœ¬å‹åŠ›"
    4. çˆ†å“é›†ä¸­åº¦ > 60% â†’ "çˆ†å“é›†ä¸­åº¦è¿‡é«˜ åˆ†æ•£é£é™©"
    5. å¤šå“ç±»ä½é”€å”® â†’ "å“ç±»ç®¡ç† ä¼˜åŒ–é…æ¯”"
    """
    query_parts = []
    
    # åŠ¨é”€ç‡æ£€æµ‹
    if kpi_data.get('åŠ¨é”€ç‡', 100) < 60:
        query_parts.append("åŠ¨é”€ç‡ä½ å¦‚ä½•ä¼˜åŒ–å•†å“ç»“æ„")
    
    # æ»é”€å æ¯”æ£€æµ‹
    if kpi_data.get('æ»é”€å æ¯”', 0) > 20:
        query_parts.append("æ»é”€å æ¯”è¿‡é«˜ æ¸…ç†åº“å­˜")
    
    # æŠ˜æ‰£æ·±åº¦æ£€æµ‹
    if kpi_data.get('å¹³å‡æŠ˜æ‰£', 0) < -20:
        query_parts.append("æŠ˜æ‰£è¿‡æ·± æˆæœ¬å‹åŠ› åˆ©æ¶¦ä¼˜åŒ–")
    
    # çˆ†å“é›†ä¸­åº¦æ£€æµ‹
    if kpi_data.get('çˆ†å“é›†ä¸­åº¦', 0) > 60:
        query_parts.append("çˆ†å“é›†ä¸­åº¦è¿‡é«˜ åˆ†æ•£é£é™©")
    
    # å“ç±»ç®¡ç†æ£€æµ‹
    low_sales_categories = [c for c in category_data if c.get('é”€å”®é¢', 0) < 1000]
    if len(low_sales_categories) > 3:
        query_parts.append("å“ç±»ç®¡ç† ä¼˜åŒ–é…æ¯”")
    
    return " ".join(query_parts) if query_parts else "é—¨åº—ç»è¥å¥åº·åº¦è¯Šæ–­"
```

**å¢å¼ºæç¤ºè¯æ„å»º**:
```python
def _build_analysis_prompt(self, ...):
    # æ—§ç‰ˆ: å§‹ç»ˆæ³¨å…¥å…¨é‡ä¸šåŠ¡çŸ¥è¯†(3000å­—ç¬¦)
    # prompt = f"{business_context}\n\n{ç”¨æˆ·æ•°æ®}\n\nè¯·åˆ†æ..."
    
    # æ–°ç‰ˆPhase 1: æ™ºèƒ½æ£€ç´¢ç›¸å…³çŸ¥è¯†
    if self.knowledge_retriever:
        # 1. æ„å»ºæ™ºèƒ½æŸ¥è¯¢
        analysis_query = self._build_retrieval_query(kpi_data, category_data, meta_data)
        
        # 2. æ£€ç´¢ç›¸å…³çŸ¥è¯†
        contextual_knowledge = self.knowledge_retriever.get_contextual_knowledge(
            query=analysis_query,
            analysis_type="é—¨åº—ç»è¥å¥åº·åº¦è¯Šæ–­"
        )
        
        # 3. æ³¨å…¥ç²¾å‡†çŸ¥è¯† (~2500å­—ç¬¦, ä»…ç›¸å…³éƒ¨åˆ†)
        prompt = f"{contextual_knowledge}\n\n{ç”¨æˆ·æ•°æ®}\n\nè¯·åˆ†æ..."
    else:
        # é™çº§æ¨¡å¼: ä½¿ç”¨å…¨é‡çŸ¥è¯†
        prompt = f"{business_context[:3000]}\n\n{ç”¨æˆ·æ•°æ®}\n\nè¯·åˆ†æ..."
```

**æ•ˆæœå¯¹æ¯”**:
| ç»´åº¦ | æ—§ç‰ˆ | Phase 1å¢å¼ºç‰ˆ |
|------|------|---------------|
| çŸ¥è¯†æ³¨å…¥æ–¹å¼ | å…¨é‡(3000å­—ç¬¦å›ºå®š) | æ™ºèƒ½æ£€ç´¢(~2500å­—ç¬¦ç›¸å…³) |
| ç›¸å…³æ€§ | ä½(å¤§é‡æ— å…³çŸ¥è¯†) | é«˜(ä»…æ£€ç´¢ç›¸å…³ç‰‡æ®µ) |
| Tokenæ¶ˆè€— | å›ºå®š3000+ | å¯å˜1500-2500 |
| åˆ†æç²¾åº¦ | æ³›åŒ–å»ºè®® | é’ˆå¯¹æ€§è¯Šæ–­ |

---

### 3. é—®é¢˜ä¿®å¤è®°å½•

#### Issue #1: Import Path Error âœ… å·²ä¿®å¤
**é”™è¯¯**: `ImportError: No module named 'langchain.text_splitter'`

**æ ¹å› **: LangChain 1.0+ é‡æ„å¯¼å…¥è·¯å¾„

**ä¿®å¤**:
```python
# æ—§ (å·²å¤±æ•ˆ)
from langchain.text_splitter import RecursiveCharacterTextSplitter

# æ–° (å·²ä¿®å¤)
from langchain_text_splitters import RecursiveCharacterTextSplitter
```

**éªŒè¯**: âœ… å¯¼å…¥æˆåŠŸ,æ— è¯­æ³•é”™è¯¯

---

## ğŸ”„ å½“å‰çŠ¶æ€

### ä»£ç å®Œæˆåº¦: 100% âœ…
- âœ… ai_knowledge_retriever.py (270è¡Œ) - å·²å®Œæˆ
- âœ… ai_analyzer.py å¢å¼ºé›†æˆ - å·²å®Œæˆ
- âœ… æ™ºèƒ½æŸ¥è¯¢æ„å»ºé€»è¾‘ - å·²å®Œæˆ
- âœ… ç¼“å­˜æœºåˆ¶ - å·²å®Œæˆ
- âœ… é™çº§æ¨¡å¼ - å·²å®Œæˆ

### æµ‹è¯•çŠ¶æ€: 90% ğŸ”„
- âœ… ä¾èµ–å®‰è£…éªŒè¯ - å·²é€šè¿‡
- âœ… ä»£ç è¯­æ³•æ£€æŸ¥ - å·²é€šè¿‡
- âœ… å¯¼å…¥è·¯å¾„ä¿®å¤ - å·²é€šè¿‡
- ğŸ”„ **åµŒå…¥æ¨¡å‹ä¸‹è½½** - è¿›è¡Œä¸­
  - æ¨¡å‹: paraphrase-multilingual-MiniLM-L12-v2
  - å¤§å°: ~420MB
  - çŠ¶æ€: é¦–æ¬¡è¿è¡Œè‡ªåŠ¨ä¸‹è½½(ä»…ä¸€æ¬¡)
  - ç¼“å­˜: ~/.cache/huggingface/

### å¾…éªŒè¯åŠŸèƒ½
1. **å‘é‡åº“æ„å»º** (éœ€æ¨¡å‹ä¸‹è½½å®Œæˆ)
   - è¾“å…¥: ai_business_context.py (2500è¡Œä¸šåŠ¡çŸ¥è¯†)
   - è¾“å‡º: ./cache/business_knowledge_vectorstore/
   
2. **æ£€ç´¢è´¨é‡æµ‹è¯•**
   ```python
   # æµ‹è¯•ç”¨ä¾‹
   query1 = "åŠ¨é”€ç‡ä½äº60% æ»é”€å æ¯”é«˜"
   # é¢„æœŸ: è¿”å›SKUç®¡ç†ã€åº“å­˜ä¼˜åŒ–ç›¸å…³çŸ¥è¯†
   
   query2 = "æŠ˜æ‰£è¿‡æ·± æˆæœ¬å‹åŠ›"
   # é¢„æœŸ: è¿”å›æˆæœ¬æ§åˆ¶ã€å®šä»·ç­–ç•¥ç›¸å…³çŸ¥è¯†
   ```

3. **ç«¯åˆ°ç«¯AIåˆ†æ**
   - ä½¿ç”¨çœŸå®Dashboardæ•°æ®
   - å¯¹æ¯”æ—§ç‰ˆ vs Phase 1å¢å¼ºç‰ˆè¾“å‡º
   - è¯„ä¼°åˆ†æç²¾å‡†åº¦æå‡

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

### çŸ¥è¯†æ³¨å…¥ä¼˜åŒ–
**åœºæ™¯1: åŠ¨é”€ç‡ä½çš„é—¨åº—**
```
æ—§ç‰ˆ: æ³¨å…¥å…¨é‡3000å­—ç¬¦(åŒ…å«æ— å…³æŠ˜æ‰£ç­–ç•¥ã€çˆ†å“ç®¡ç†ç­‰)
æ–°ç‰ˆ: æ£€ç´¢åˆ°5ä¸ªç›¸å…³ç‰‡æ®µ:
  - SKUåŠ¨é”€ç‡å®šä¹‰ä¸ä¼˜åŒ–å»ºè®®
  - æ»é”€å•†å“è¯†åˆ«æ ‡å‡†
  - å•†å“ç»“æ„è°ƒæ•´ç­–ç•¥
  - åº“å­˜å‘¨è½¬ç‡æå‡æ–¹æ³•
  - å¤šè§„æ ¼å•†å“ç®¡ç†æŠ€å·§
```

**åœºæ™¯2: æŠ˜æ‰£æ·±åº¦è¿‡å¤§çš„é—¨åº—**
```
æ—§ç‰ˆ: åŒæ ·çš„3000å­—ç¬¦å…¨é‡çŸ¥è¯†
æ–°ç‰ˆ: æ£€ç´¢åˆ°5ä¸ªç›¸å…³ç‰‡æ®µ:
  - æŠ˜æ‰£æ·±åº¦è®¡ç®—æ–¹æ³•
  - æˆæœ¬å‹åŠ›åˆ†ææ¨¡å‹
  - åˆ©æ¶¦ä¿æŠ¤ç­–ç•¥
  - æ´»åŠ¨å•†å“å®šä»·å»ºè®®
  - éæ´»åŠ¨å•†å“ä¼˜åŒ–æ–¹å‘
```

### Tokenæ•ˆç‡æå‡
| æŒ‡æ ‡ | æ—§ç‰ˆ | Phase 1 | æå‡å¹…åº¦ |
|------|------|---------|----------|
| å¹³å‡æç¤ºè¯é•¿åº¦ | 3200 tokens | 2000 tokens | -37.5% |
| æ— å…³çŸ¥è¯†æ¯”ä¾‹ | ~60% | ~10% | â¬‡ï¸ 83% |
| APIè°ƒç”¨æˆæœ¬ | åŸºå‡† | -37.5% | èŠ‚çº¦37.5% |

---

## ğŸš€ ä½¿ç”¨æŒ‡å—

### å¿«é€Ÿå¯åŠ¨
```powershell
# 1. ç¡®ä¿åœ¨è™šæ‹Ÿç¯å¢ƒä¸­
cd "D:\Python1\O2O_Analysis\O2Oæ•°æ®åˆ†æ\é—¨åº—åŸºç¡€æ•°æ®åˆ†æ"

# 2. å¯åŠ¨Dashboard (è‡ªåŠ¨åŠ è½½Phase 1å¢å¼º)
.\.venv\Scripts\python.exe dashboard_v2.py

# æ§åˆ¶å°è¾“å‡º:
# âœ… å‘é‡æ£€ç´¢æ¨¡å—å·²åŠ è½½
# âœ… å‘é‡æ£€ç´¢å™¨å·²åŠ è½½  â† æ–°å¢
# âœ… AIåˆ†æå™¨å·²å°±ç»ª
```

### æ‰‹åŠ¨æµ‹è¯•
```python
# test_phase1.py
from ai_knowledge_retriever import get_knowledge_retriever

retriever = get_knowledge_retriever()

# æµ‹è¯•æ£€ç´¢
query = "åŠ¨é”€ç‡ä½äº60%æ€ä¹ˆåŠ?"
knowledge = retriever.get_contextual_knowledge(query, "é—¨åº—è¯Šæ–­")

print(f"æ£€ç´¢åˆ° {len(knowledge)} å­—ç¬¦ç›¸å…³çŸ¥è¯†:")
print(knowledge[:500])
```

### é…ç½®é€‰é¡¹
```python
# ai_analyzer.py é¡¶éƒ¨
VECTOR_RETRIEVAL_ENABLED = True  # å…³é—­å¯åˆ‡å›æ—§ç‰ˆ

# ai_knowledge_retriever.py
class BusinessKnowledgeRetriever:
    def __init__(self, 
                 cache_dir="./cache",           # ç¼“å­˜ç›®å½•
                 chunk_size=500,                # æ–‡æœ¬å—å¤§å°
                 chunk_overlap=50,              # é‡å å­—ç¬¦æ•°
                 top_k=5):                      # è¿”å›ç‰‡æ®µæ•°
```

---

## ğŸ“ æŠ€æœ¯ç»†èŠ‚

### å‘é‡åŒ–æµç¨‹
```
1. åŠ è½½ai_business_context.py (2500è¡Œ)
   â†“
2. RecursiveCharacterTextSplitteråˆ†å‰²
   - æŒ‰æ®µè½ã€å¥å­ã€æ ‡ç‚¹ç¬¦å·åˆ†å‰²
   - 500å­—ç¬¦/å—, 50å­—ç¬¦é‡å 
   - ç”Ÿæˆ ~200ä¸ªæ–‡æœ¬å—
   â†“
3. HuggingFaceEmbeddingsç¼–ç 
   - æ¨¡å‹: paraphrase-multilingual-MiniLM-L12-v2
   - æ¯å— â†’ 384ç»´å‘é‡
   â†“
4. FAISSç´¢å¼•æ„å»º
   - ä½¿ç”¨L2è·ç¦»
   - ä¿å­˜åˆ°./cache/
   â†“
5. æŸ¥è¯¢æ—¶ç›¸ä¼¼åº¦æœç´¢
   - query â†’ 384ç»´å‘é‡
   - FAISS.similarity_search_with_score()
   - è¿”å›top 5æœ€ç›¸ä¼¼å—
```

### ç¼“å­˜æœºåˆ¶
```python
# é¦–æ¬¡è¿è¡Œ
1. æ£€æµ‹ ./cache/business_knowledge_vectorstore/ ä¸å­˜åœ¨
2. æ„å»ºå‘é‡åº“ (~30ç§’)
3. ä¿å­˜åˆ°ç¼“å­˜

# åç»­è¿è¡Œ
1. æ£€æµ‹ç¼“å­˜å­˜åœ¨
2. ç›´æ¥åŠ è½½ (<1ç§’)
3. æ— éœ€é‡æ–°æ„å»º
```

### é™çº§ç­–ç•¥
```python
if VECTOR_SEARCH_AVAILABLE:
    # ä½¿ç”¨å‘é‡æ£€ç´¢
    knowledge = retriever.get_contextual_knowledge(...)
else:
    # é™çº§åˆ°å…¨é‡çŸ¥è¯†
    from ai_business_context import get_business_context
    knowledge = get_business_context()[:3000]
```

---

## ğŸ¯ ä¸‹ä¸€æ­¥è®¡åˆ’

### Phase 2: PandasAIé›†æˆ (å»ºè®®)
```python
from pandasai import Agent

# è‡ªç„¶è¯­è¨€æŸ¥è¯¢æ•°æ®
agent = Agent(df)
result = agent.chat("å“ªäº›å•†å“çš„åŠ¨é”€ç‡ä½äº60%?")
```

### Phase 3: å¤šæ¨¡æ€åˆ†æ (å¯é€‰)
- é›†æˆPlotlyå›¾è¡¨ç”Ÿæˆ
- è‡ªåŠ¨è¯†åˆ«æ•°æ®æ¨¡å¼
- å¯è§†åŒ–æ¨èå¼•æ“

---

## ğŸ“ æ”¯æŒä¸åé¦ˆ

**é‡åˆ°é—®é¢˜?**
1. æ£€æŸ¥`./cache/`ç›®å½•æƒé™
2. éªŒè¯è™šæ‹Ÿç¯å¢ƒä¾èµ–: `.\.venv\Scripts\pip.exe list`
3. æŸ¥çœ‹æ§åˆ¶å°è¾“å‡º: `âœ… å‘é‡æ£€ç´¢å™¨å·²åŠ è½½` æˆ– `âš ï¸ é™çº§æ¨¡å¼`

**æ€§èƒ½è°ƒä¼˜?**
- å‡å°‘top_k (é»˜è®¤5 â†’ 3): æ›´å¿«ä½†å¯èƒ½ä¸¢å¤±ç›¸å…³çŸ¥è¯†
- å¢å¤§chunk_size (500 â†’ 800): æ›´å®Œæ•´ä½†æ›´æ¨¡ç³Š
- åˆ‡æ¢åµŒå…¥æ¨¡å‹: `all-MiniLM-L6-v2` (æ›´å¿«, è‹±æ–‡ä¼˜å…ˆ)

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: 2024å¹´10æœˆ27æ—¥  
**ç‰ˆæœ¬**: Phase 1 v1.0  
**çŠ¶æ€**: âœ… ä»£ç å®Œæˆ, ğŸ”„ æµ‹è¯•è¿›è¡Œä¸­
