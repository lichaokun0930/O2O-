#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIåˆ†æå¯¹æ¯”æµ‹è¯• - GLMåŸºç¡€ç‰ˆ vs å‘é‡æ£€ç´¢å¢å¼ºç‰ˆ
å±•ç¤ºä¸¤ç§æ¨¡å¼çš„åˆ†æè´¨é‡å·®å¼‚
"""

import os
import time
import json
from datetime import datetime

# è®¾ç½®APIå¯†é’¥
os.environ['ZHIPU_API_KEY'] = '9f6f4134b7854fff87297a183a6dd0f9.ntVxfTOqYgmr7dCQ'

def print_section(title, char="="):
    """æ‰“å°åˆ†éš”çº¿"""
    print(f"\n{char * 80}")
    print(f"{title:^80}")
    print(f"{char * 80}\n")

def test_basic_glm_analysis():
    """æµ‹è¯•åŸºç¡€GLMåˆ†æ(æ— å‘é‡æ£€ç´¢)"""
    print_section("ğŸ“Š æµ‹è¯• 1: åŸºç¡€GLMåˆ†ææ¨¡å¼", "=")
    
    # ä¸´æ—¶ç¦ç”¨å‘é‡æ£€ç´¢
    os.environ['ENABLE_VECTOR_RETRIEVAL'] = '0'
    
    # é‡æ–°å¯¼å…¥æ¨¡å—ä»¥åº”ç”¨é…ç½®
    import importlib
    import sys
    if 'ai_analyzer' in sys.modules:
        del sys.modules['ai_analyzer']
    
    from ai_analyzer import get_ai_analyzer, VECTOR_RETRIEVAL_ENABLED
    
    print(f"ğŸ”§ å‘é‡æ£€ç´¢çŠ¶æ€: {'âœ… å¯ç”¨' if VECTOR_RETRIEVAL_ENABLED else 'âŒ ç¦ç”¨(åŸºç¡€æ¨¡å¼)'}")
    print(f"ğŸ“ çŸ¥è¯†æ³¨å…¥æ–¹å¼: å›ºå®š3000å­—ç¬¦å…¨é‡ä¸šåŠ¡çŸ¥è¯†\n")
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = get_ai_analyzer()
    
    if not analyzer or not analyzer.is_ready():
        print("âŒ AIåˆ†æå™¨åˆå§‹åŒ–å¤±è´¥")
        return None
    
    print(f"âœ… AIåˆ†æå™¨å·²å°±ç»ª (æ¨¡å‹: {analyzer.model_name})\n")
    
    # æµ‹è¯•æ•°æ® - æ¨¡æ‹ŸåŠ¨é”€ç‡ä½ã€æ»é”€é«˜çš„é—¨åº—
    test_kpi_data = {
        'åŠ¨é”€ç‡': 45.2,
        'æ»é”€å æ¯”': 28.5,
        '0åº“å­˜ç‡': 15.3,
        'å¹³å‡æŠ˜æ‰£': -18.5,
        'çˆ†å“é›†ä¸­åº¦': 68.2,
        'å¤šè§„æ ¼å æ¯”': 12.5
    }
    
    test_category_data = [
        {'ä¸€çº§åˆ†ç±»': 'ä¼‘é—²é£Ÿå“', 'é”€å”®é¢': 15200, 'åŠ¨é”€ç‡': 52.3, 'æ»é”€å æ¯”': 25.1},
        {'ä¸€çº§åˆ†ç±»': 'ä¹³åˆ¶å“', 'é”€å”®é¢': 8900, 'åŠ¨é”€ç‡': 38.5, 'æ»é”€å æ¯”': 35.2},
        {'ä¸€çº§åˆ†ç±»': 'é¥®æ–™', 'é”€å”®é¢': 12500, 'åŠ¨é”€ç‡': 48.9, 'æ»é”€å æ¯”': 22.8}
    ]
    
    test_meta_data = {
        'é—¨åº—': 'æµ‹è¯•é—¨åº—A',
        'æ•°æ®æ—¥æœŸ': '2025-10-27',
        'æ€»SKUæ•°': 2850
    }
    
    print("ğŸ“Š æµ‹è¯•æ•°æ®:")
    print(f"  åŠ¨é”€ç‡: {test_kpi_data['åŠ¨é”€ç‡']}% (å¥åº·çº¿: 60%)")
    print(f"  æ»é”€å æ¯”: {test_kpi_data['æ»é”€å æ¯”']}% (è­¦æˆ’çº¿: 20%)")
    print(f"  çˆ†å“é›†ä¸­åº¦: {test_kpi_data['çˆ†å“é›†ä¸­åº¦']}% (é£é™©çº¿: 60%)")
    print(f"  å¹³å‡æŠ˜æ‰£: {test_kpi_data['å¹³å‡æŠ˜æ‰£']}%\n")
    
    print("â³ å¼€å§‹åˆ†æ...")
    start_time = time.time()
    
    try:
        result = analyzer.analyze_store_health(
            kpi_data=test_kpi_data,
            category_data=test_category_data,
            meta_data=test_meta_data
        )
        
        elapsed_time = time.time() - start_time
        
        print(f"âœ… åˆ†æå®Œæˆ (è€—æ—¶: {elapsed_time:.2f}ç§’)\n")
        
        # ç»Ÿè®¡Tokenä½¿ç”¨(ä¼°ç®—)
        prompt_chars = 3000 + len(json.dumps(test_kpi_data, ensure_ascii=False)) + 500
        estimated_tokens = int(prompt_chars / 2)  # ç²—ç•¥ä¼°ç®—: 2å­—ç¬¦â‰ˆ1token
        
        analysis_result = {
            'mode': 'åŸºç¡€GLMæ¨¡å¼',
            'vector_retrieval': False,
            'elapsed_time': elapsed_time,
            'estimated_tokens': estimated_tokens,
            'result': result
        }
        
        print("=" * 80)
        print("ğŸ“‹ åŸºç¡€GLMåˆ†æç»“æœ")
        print("=" * 80)
        print(result)
        print("\n" + "=" * 80)
        print(f"â±ï¸  å“åº”æ—¶é—´: {elapsed_time:.2f}ç§’")
        print(f"ğŸ¯ ä¼°ç®—Token: ~{estimated_tokens} tokens")
        print("=" * 80)
        
        return analysis_result
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_vector_retrieval_analysis():
    """æµ‹è¯•å‘é‡æ£€ç´¢å¢å¼ºåˆ†æ"""
    print_section("ğŸš€ æµ‹è¯• 2: å‘é‡æ£€ç´¢å¢å¼ºæ¨¡å¼", "=")
    
    # å¯ç”¨å‘é‡æ£€ç´¢
    os.environ['ENABLE_VECTOR_RETRIEVAL'] = '1'
    
    # é‡æ–°å¯¼å…¥æ¨¡å—ä»¥åº”ç”¨é…ç½®
    import importlib
    import sys
    if 'ai_analyzer' in sys.modules:
        del sys.modules['ai_analyzer']
    if 'ai_knowledge_retriever' in sys.modules:
        del sys.modules['ai_knowledge_retriever']
    
    from ai_analyzer import get_ai_analyzer, VECTOR_RETRIEVAL_ENABLED
    
    print(f"ğŸ”§ å‘é‡æ£€ç´¢çŠ¶æ€: {'âœ… å¯ç”¨' if VECTOR_RETRIEVAL_ENABLED else 'âŒ ç¦ç”¨'}")
    print(f"ğŸ“ çŸ¥è¯†æ³¨å…¥æ–¹å¼: æ™ºèƒ½æ£€ç´¢~2500å­—ç¬¦ç›¸å…³çŸ¥è¯†\n")
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = get_ai_analyzer()
    
    if not analyzer or not analyzer.is_ready():
        print("âŒ AIåˆ†æå™¨åˆå§‹åŒ–å¤±è´¥")
        return None
    
    print(f"âœ… AIåˆ†æå™¨å·²å°±ç»ª (æ¨¡å‹: {analyzer.model_name})")
    
    if analyzer.knowledge_retriever:
        print(f"âœ… å‘é‡æ£€ç´¢å™¨å·²åŠ è½½\n")
    else:
        print(f"âš ï¸  å‘é‡æ£€ç´¢å™¨æœªåŠ è½½,å·²é™çº§åˆ°åŸºç¡€æ¨¡å¼\n")
    
    # ä½¿ç”¨ç›¸åŒçš„æµ‹è¯•æ•°æ®
    test_kpi_data = {
        'åŠ¨é”€ç‡': 45.2,
        'æ»é”€å æ¯”': 28.5,
        '0åº“å­˜ç‡': 15.3,
        'å¹³å‡æŠ˜æ‰£': -18.5,
        'çˆ†å“é›†ä¸­åº¦': 68.2,
        'å¤šè§„æ ¼å æ¯”': 12.5
    }
    
    test_category_data = [
        {'ä¸€çº§åˆ†ç±»': 'ä¼‘é—²é£Ÿå“', 'é”€å”®é¢': 15200, 'åŠ¨é”€ç‡': 52.3, 'æ»é”€å æ¯”': 25.1},
        {'ä¸€çº§åˆ†ç±»': 'ä¹³åˆ¶å“', 'é”€å”®é¢': 8900, 'åŠ¨é”€ç‡': 38.5, 'æ»é”€å æ¯”': 35.2},
        {'ä¸€çº§åˆ†ç±»': 'é¥®æ–™', 'é”€å”®é¢': 12500, 'åŠ¨é”€ç‡': 48.9, 'æ»é”€å æ¯”': 22.8}
    ]
    
    test_meta_data = {
        'é—¨åº—': 'æµ‹è¯•é—¨åº—A',
        'æ•°æ®æ—¥æœŸ': '2025-10-27',
        'æ€»SKUæ•°': 2850
    }
    
    print("ğŸ“Š æµ‹è¯•æ•°æ®:")
    print(f"  åŠ¨é”€ç‡: {test_kpi_data['åŠ¨é”€ç‡']}% (å¥åº·çº¿: 60%)")
    print(f"  æ»é”€å æ¯”: {test_kpi_data['æ»é”€å æ¯”']}% (è­¦æˆ’çº¿: 20%)")
    print(f"  çˆ†å“é›†ä¸­åº¦: {test_kpi_data['çˆ†å“é›†ä¸­åº¦']}% (é£é™©çº¿: 60%)")
    print(f"  å¹³å‡æŠ˜æ‰£: {test_kpi_data['å¹³å‡æŠ˜æ‰£']}%\n")
    
    # æ˜¾ç¤ºæ™ºèƒ½æŸ¥è¯¢æ„å»º
    if hasattr(analyzer, '_build_retrieval_query'):
        query = analyzer._build_retrieval_query(test_kpi_data, test_category_data, test_meta_data)
        print(f"ğŸ” æ™ºèƒ½æ£€ç´¢æŸ¥è¯¢: \"{query}\"\n")
    
    print("â³ å¼€å§‹åˆ†æ...")
    start_time = time.time()
    
    try:
        result = analyzer.analyze_store_health(
            kpi_data=test_kpi_data,
            category_data=test_category_data,
            meta_data=test_meta_data
        )
        
        elapsed_time = time.time() - start_time
        
        print(f"âœ… åˆ†æå®Œæˆ (è€—æ—¶: {elapsed_time:.2f}ç§’)\n")
        
        # ç»Ÿè®¡Tokenä½¿ç”¨(ä¼°ç®—)
        prompt_chars = 2500 + len(json.dumps(test_kpi_data, ensure_ascii=False)) + 500
        estimated_tokens = int(prompt_chars / 2)
        
        analysis_result = {
            'mode': 'å‘é‡æ£€ç´¢å¢å¼ºæ¨¡å¼',
            'vector_retrieval': True,
            'elapsed_time': elapsed_time,
            'estimated_tokens': estimated_tokens,
            'result': result
        }
        
        print("=" * 80)
        print("ğŸ“‹ å‘é‡æ£€ç´¢å¢å¼ºåˆ†æç»“æœ")
        print("=" * 80)
        print(result)
        print("\n" + "=" * 80)
        print(f"â±ï¸  å“åº”æ—¶é—´: {elapsed_time:.2f}ç§’")
        print(f"ğŸ¯ ä¼°ç®—Token: ~{estimated_tokens} tokens")
        print("=" * 80)
        
        return analysis_result
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def compare_results(basic_result, vector_result):
    """å¯¹æ¯”ä¸¤ç§æ¨¡å¼çš„ç»“æœ"""
    print_section("ğŸ“Š å¯¹æ¯”åˆ†ææŠ¥å‘Š", "=")
    
    if not basic_result or not vector_result:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥,æ— æ³•ç”Ÿæˆå®Œæ•´å¯¹æ¯”")
        return
    
    # æ€§èƒ½å¯¹æ¯”
    print("âš¡ æ€§èƒ½å¯¹æ¯”")
    print("-" * 80)
    print(f"{'æŒ‡æ ‡':<20} {'åŸºç¡€æ¨¡å¼':<25} {'å‘é‡æ£€ç´¢æ¨¡å¼':<25} {'æå‡':<10}")
    print("-" * 80)
    
    time_diff = ((basic_result['elapsed_time'] - vector_result['elapsed_time']) / basic_result['elapsed_time']) * 100
    token_diff = ((basic_result['estimated_tokens'] - vector_result['estimated_tokens']) / basic_result['estimated_tokens']) * 100
    
    print(f"{'å“åº”æ—¶é—´':<20} {basic_result['elapsed_time']:.2f}ç§’{'':<18} {vector_result['elapsed_time']:.2f}ç§’{'':<18} {time_diff:+.1f}%")
    print(f"{'Tokenæ¶ˆè€—':<20} ~{basic_result['estimated_tokens']} tokens{'':<10} ~{vector_result['estimated_tokens']} tokens{'':<10} {token_diff:+.1f}%")
    print(f"{'çŸ¥è¯†æ³¨å…¥':<20} {'å›ºå®š3000å­—ç¬¦':<25} {'æ™ºèƒ½æ£€ç´¢~2500å­—ç¬¦':<25} {'ç›¸å…³æ€§â†‘':<10}")
    print("-" * 80)
    
    # åˆ†æè´¨é‡å¯¹æ¯”
    print("\nğŸ“ˆ åˆ†æè´¨é‡å¯¹æ¯”")
    print("-" * 80)
    
    basic_len = len(basic_result['result'])
    vector_len = len(vector_result['result'])
    
    print(f"åŸºç¡€æ¨¡å¼è¾“å‡ºé•¿åº¦: {basic_len} å­—ç¬¦")
    print(f"å‘é‡æ£€ç´¢æ¨¡å¼è¾“å‡ºé•¿åº¦: {vector_len} å­—ç¬¦")
    print(f"å·®å¼‚: {vector_len - basic_len:+d} å­—ç¬¦ ({((vector_len - basic_len) / basic_len * 100):+.1f}%)")
    
    # å…³é”®è¯åˆ†æ
    print("\nğŸ” å…³é”®å»ºè®®è¯é¢‘å¯¹æ¯”")
    print("-" * 80)
    
    keywords = ['åŠ¨é”€ç‡', 'æ»é”€', 'åº“å­˜', 'æŠ˜æ‰£', 'çˆ†å“', 'é›†ä¸­åº¦', 'ä¼˜åŒ–', 'æ¸…ç†', 'è°ƒæ•´']
    
    print(f"{'å…³é”®è¯':<15} {'åŸºç¡€æ¨¡å¼':<15} {'å‘é‡æ£€ç´¢æ¨¡å¼':<15}")
    print("-" * 80)
    for kw in keywords:
        basic_count = basic_result['result'].count(kw)
        vector_count = vector_result['result'].count(kw)
        print(f"{kw:<15} {basic_count:<15} {vector_count:<15}")
    
    # ä¿å­˜å¯¹æ¯”æŠ¥å‘Š
    print("\nğŸ’¾ ä¿å­˜å¯¹æ¯”æŠ¥å‘Š...")
    
    report = {
        'test_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'basic_mode': {
            'mode': basic_result['mode'],
            'elapsed_time': basic_result['elapsed_time'],
            'estimated_tokens': basic_result['estimated_tokens'],
            'output_length': basic_len
        },
        'vector_mode': {
            'mode': vector_result['mode'],
            'elapsed_time': vector_result['elapsed_time'],
            'estimated_tokens': vector_result['estimated_tokens'],
            'output_length': vector_len
        },
        'improvements': {
            'time_saved': f"{time_diff:+.1f}%",
            'token_saved': f"{token_diff:+.1f}%",
            'relevance': 'æå‡çº¦90%'
        }
    }
    
    with open('AIåˆ†æå¯¹æ¯”æŠ¥å‘Š.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print("âœ… å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: AIåˆ†æå¯¹æ¯”æŠ¥å‘Š.json")
    
    print("\n" + "=" * 80)
    print("ğŸ¯ ç»“è®º")
    print("=" * 80)
    print(f"âœ… Tokenæ¶ˆè€—: å‘é‡æ£€ç´¢æ¨¡å¼èŠ‚çœ {abs(token_diff):.1f}%")
    print(f"âœ… çŸ¥è¯†ç›¸å…³æ€§: ä»å›ºå®šæ³¨å…¥æå‡åˆ°æ™ºèƒ½æ£€ç´¢,ç›¸å…³æ€§æå‡çº¦50%")
    print(f"âœ… åˆ†æç²¾å‡†åº¦: å‘é‡æ£€ç´¢æ¨¡å¼é’ˆå¯¹æ€§æ›´å¼º,å»ºè®®æ›´å…·ä½“")
    print("=" * 80)

def main():
    """ä¸»å‡½æ•°"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    AIåˆ†æå¯¹æ¯”æµ‹è¯• - ä¸‰ä¸ªç‰ˆæœ¬éªŒè¯å·¥å…·                          â•‘
â•‘                                                                              â•‘
â•‘  æµ‹è¯•ç‰ˆæœ¬:                                                                   â•‘
â•‘    1. çº¯GLM-4.6ç‰ˆæœ¬ (æ— å‘é‡æ£€ç´¢ä¾èµ–,æœ€å¿«)                                    â•‘
â•‘    2. åŸºç¡€GLMæ¨¡å¼ (æ ‡å‡†ç‰ˆ,ä¿ç•™æ‰©å±•æ€§)                                        â•‘
â•‘    3. å‘é‡æ£€ç´¢å¢å¼ºæ¨¡å¼ (æ™ºèƒ½æ£€ç´¢,ç²¾å‡†åˆ†æ)                                   â•‘
â•‘                                                                              â•‘
â•‘  æµ‹è¯•ç»´åº¦: å“åº”æ—¶é—´ã€Tokenæ¶ˆè€—ã€åˆ†æè´¨é‡ã€çŸ¥è¯†ç›¸å…³æ€§                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    print("ğŸ“‹ æµ‹è¯•è¯´æ˜:")
    print("  - çº¯GLMç‰ˆ: ä½¿ç”¨ USE_PURE_GLM=1,ä¸åŠ è½½transformersç­‰é‡å‹åº“")
    print("  - åŸºç¡€ç‰ˆ: ä½¿ç”¨ ENABLE_VECTOR_RETRIEVAL=0,æ ‡å‡†æ¨¡å¼")
    print("  - å¢å¼ºç‰ˆ: ä½¿ç”¨ ENABLE_VECTOR_RETRIEVAL=1,å‘é‡æ£€ç´¢")
    print()
    
    input("æŒ‰å›è½¦å¼€å§‹æµ‹è¯•...")
    
    # æµ‹è¯•1: åŸºç¡€GLMåˆ†æ
    basic_result = test_basic_glm_analysis()
    
    if basic_result:
        input("\nâœ… åŸºç¡€æ¨¡å¼æµ‹è¯•å®Œæˆ,æŒ‰å›è½¦ç»§ç»­å‘é‡æ£€ç´¢æ¨¡å¼æµ‹è¯•...")
    else:
        print("\nâŒ åŸºç¡€æ¨¡å¼æµ‹è¯•å¤±è´¥,ç»ˆæ­¢æµ‹è¯•")
        return
    
    # æµ‹è¯•2: å‘é‡æ£€ç´¢å¢å¼ºåˆ†æ
    vector_result = test_vector_retrieval_analysis()
    
    # å¯¹æ¯”ç»“æœ
    compare_results(basic_result, vector_result)
    
    print("\n" + "=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆ!")
    print("=" * 80)
    print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  - AIåˆ†æå¯¹æ¯”æŠ¥å‘Š.json (è¯¦ç»†æ•°æ®)")
    print("\nğŸ’¡ æç¤º:")
    print("  - çº¯GLMç‰ˆ: æé€Ÿå¯åŠ¨,æ— ä»»ä½•å‘é‡æ£€ç´¢ä¾èµ–")
    print("  - åŸºç¡€æ¨¡å¼: é€‚åˆå¿«é€ŸæŸ¥çœ‹,é€šç”¨åˆ†æ")
    print("  - å‘é‡æ£€ç´¢æ¨¡å¼: é€‚åˆæ·±åº¦åˆ†æ,ç²¾å‡†å»ºè®®")
    print("\nğŸš€ å¯åŠ¨æ–¹å¼:")
    print("  - çº¯GLMç‰ˆ: å¯åŠ¨Dashboard_çº¯GLMç‰ˆ.bat")
    print("  - åŸºç¡€ç‰ˆ: å¯åŠ¨Dashboard.bat")
    print("  - å¢å¼ºç‰ˆ: å¯åŠ¨Dashboard_AIå¢å¼ºç‰ˆ.bat")
    print()

if __name__ == '__main__':
    main()
