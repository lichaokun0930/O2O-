"""
æ•°æ®ç¼“å­˜ç®¡ç†å™¨ - P0+P2ä¼˜åŒ–
"""
import pickle
import hashlib
from pathlib import Path
import logging

logger = logging.getLogger(__name__)


class DataCache:
    """æ•°æ®ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir='./cache'):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        logger.info(f"ç¼“å­˜ç›®å½•: {self.cache_dir.absolute()}")
    
    def _get_file_hash(self, file_path):
        """è®¡ç®—æ–‡ä»¶MD5å“ˆå¸Œ"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def _get_cache_path(self, file_path):
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        file_hash = self._get_file_hash(file_path)
        return self.cache_dir / f"{Path(file_path).stem}_{file_hash}.cache"
    
    def get(self, file_path):
        """
        è·å–ç¼“å­˜æ•°æ®
        
        Args:
            file_path: åŸå§‹æ–‡ä»¶è·¯å¾„
        
        Returns:
            ç¼“å­˜çš„æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        try:
            cache_path = self._get_cache_path(file_path)
            if cache_path.exists():
                logger.info(f"âœ… ä½¿ç”¨ç¼“å­˜æ•°æ®: {cache_path.name}")
                with open(cache_path, 'rb') as f:
                    return pickle.load(f)
            return None
        except Exception as e:
            logger.warning(f"è¯»å–ç¼“å­˜å¤±è´¥: {e}")
            return None
    
    def set(self, file_path, data):
        """
        ä¿å­˜æ•°æ®åˆ°ç¼“å­˜
        
        Args:
            file_path: åŸå§‹æ–‡ä»¶è·¯å¾„
            data: è¦ç¼“å­˜çš„æ•°æ®
        """
        try:
            cache_path = self._get_cache_path(file_path)
            with open(cache_path, 'wb') as f:
                pickle.dump(data, f)
            size_mb = cache_path.stat().st_size / (1024 * 1024)
            logger.info(f"ğŸ’¾ ç¼“å­˜å·²ä¿å­˜: {cache_path.name} ({size_mb:.2f}MB)")
        except Exception as e:
            logger.error(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
    
    def clear(self):
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜æ–‡ä»¶"""
        count = 0
        for cache_file in self.cache_dir.glob('*.cache'):
            cache_file.unlink()
            count += 1
        logger.info(f"ğŸ—‘ï¸ å·²æ¸…é™¤ {count} ä¸ªç¼“å­˜æ–‡ä»¶")
        return count
    
    def get_cache_size(self):
        """è·å–ç¼“å­˜æ€»å¤§å°ï¼ˆMBï¼‰"""
        total_size = sum(f.stat().st_size for f in self.cache_dir.glob('*.cache'))
        return total_size / (1024 * 1024)
    
    def get_cache_count(self):
        """è·å–ç¼“å­˜æ–‡ä»¶æ•°é‡"""
        return len(list(self.cache_dir.glob('*.cache')))
