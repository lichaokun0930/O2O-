# -*- coding: utf-8 -*-
"""
åŸå¸‚æ–°å¢ç«å¯¹åˆ†æå™¨
æä¾›å„ç§ç»Ÿè®¡åˆ†æåŠŸèƒ½
"""

import pandas as pd
import numpy as np
import logging
import re
from collections import Counter

logger = logging.getLogger('dashboard')


class CompetitorAnalyzer:
    """ç«å¯¹åˆ†æå™¨ - æ‰§è¡Œå„ç§ç»Ÿè®¡åˆ†æ"""
    
    def __init__(self, df: pd.DataFrame, store_df: pd.DataFrame = None):
        """åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            df: é•¿è¡¨æ ¼å¼çš„ç«å¯¹æ•°æ®ï¼ˆæ¯è¡Œä¸€ä¸ªç«å¯¹ï¼‰
            store_df: é—¨åº—æ±‡æ€»æ•°æ®ï¼ˆå¯é€‰ï¼Œç”¨äºé—¨åº—çº§åˆ«ç»Ÿè®¡ï¼‰
        """
        self.df = df
        self.store_df = store_df
        logger.info(f"âœ… CompetitorAnalyzeråˆå§‹åŒ–: {len(df)}æ¡ç«å¯¹è®°å½•")
    
    def get_city_summary(self) -> pd.DataFrame:
        """è·å–åŸå¸‚ç»´åº¦æ±‡æ€»
        
        Returns:
            DataFrame: åŸå¸‚ | é—¨åº—æ•° | 5kmå†…ç«å¯¹æ€»æ•° | æ–°å¢ç«å¯¹æ•° | å æ¯”
        """
        if len(self.df) == 0:
            return pd.DataFrame(columns=['åŸå¸‚', 'é—¨åº—æ•°', '5kmå†…ç«å¯¹æ€»æ•°', 'æ–°å¢ç«å¯¹æ•°', 'å æ¯”'])
        
        if self.store_df is not None:
            # ä½¿ç”¨é—¨åº—æ±‡æ€»æ•°æ®
            city_stats = self.store_df.groupby('åŸå¸‚').agg({
                'é—¨åº—åç§°': 'count',
                '5kmå†…ç«å¯¹æ•°é‡': 'sum',
                'è¿‘15å¤©5kmå†…æ–°å¢ç«å¯¹æ•°é‡': 'sum'
            }).reset_index()
            city_stats.columns = ['åŸå¸‚', 'é—¨åº—æ•°', '5kmå†…ç«å¯¹æ€»æ•°', 'æ–°å¢ç«å¯¹æ•°']
        else:
            # ä»é•¿è¡¨æ•°æ®è®¡ç®—
            city_stats = self.df.groupby('åŸå¸‚').agg({
                'é—¨åº—åç§°': 'nunique',
                '5kmå†…ç«å¯¹æ•°é‡': 'first',  # æ¯ä¸ªé—¨åº—çš„å€¼ç›¸åŒ
                'ç«å¯¹åç§°': 'count'
            }).reset_index()
            city_stats.columns = ['åŸå¸‚', 'é—¨åº—æ•°', '5kmå†…ç«å¯¹æ€»æ•°', 'æ–°å¢ç«å¯¹æ•°']
        
        # è®¡ç®—å æ¯”
        total_new = city_stats['æ–°å¢ç«å¯¹æ•°'].sum()
        if total_new > 0:
            city_stats['å æ¯”'] = (city_stats['æ–°å¢ç«å¯¹æ•°'] / total_new * 100).round(2)
        else:
            city_stats['å æ¯”'] = 0.0
        
        # æŒ‰æ–°å¢ç«å¯¹æ•°é™åºæ’åˆ—
        city_stats = city_stats.sort_values('æ–°å¢ç«å¯¹æ•°', ascending=False)
        
        return city_stats
    
    def get_brand_ranking(self, top_n: int = 10) -> pd.DataFrame:
        """è·å–å“ç‰Œæ’è¡Œ
        
        Args:
            top_n: è¿”å›å‰Nä¸ªå“ç‰Œ
            
        Returns:
            DataFrame: å“ç‰Œåç§° | å‡ºç°æ¬¡æ•° | å æ¯”
        """
        if len(self.df) == 0:
            return pd.DataFrame(columns=['å“ç‰Œåç§°', 'å‡ºç°æ¬¡æ•°', 'å æ¯”'])
        
        # ç»Ÿè®¡å“ç‰Œå‡ºç°æ¬¡æ•°
        brand_counts = self.df['ç«å¯¹åç§°'].value_counts().reset_index()
        brand_counts.columns = ['å“ç‰Œåç§°', 'å‡ºç°æ¬¡æ•°']
        
        # è®¡ç®—å æ¯”
        total = brand_counts['å‡ºç°æ¬¡æ•°'].sum()
        if total > 0:
            brand_counts['å æ¯”'] = (brand_counts['å‡ºç°æ¬¡æ•°'] / total * 100).round(2)
        else:
            brand_counts['å æ¯”'] = 0.0
        
        return brand_counts.head(top_n)
    
    def get_brand_city_distribution(self, brand_name: str) -> pd.DataFrame:
        """è·å–æŒ‡å®šå“ç‰Œåœ¨å„åŸå¸‚çš„åˆ†å¸ƒ
        
        Args:
            brand_name: å“ç‰Œåç§°
            
        Returns:
            DataFrame: åŸå¸‚ | æ•°é‡
        """
        brand_df = self.df[self.df['ç«å¯¹åç§°'] == brand_name]
        distribution = brand_df.groupby('åŸå¸‚').size().reset_index(name='æ•°é‡')
        return distribution.sort_values('æ•°é‡', ascending=False)
    
    def get_business_circle_analysis(self) -> pd.DataFrame:
        """è·å–å•†åœˆç±»å‹åˆ†æ
        
        Returns:
            DataFrame: å•†åœˆç±»å‹ | é—¨åº—æ•° | å¹³å‡ç«å¯¹æ•° | å¹³å‡æ–°å¢ç«å¯¹æ•°
        """
        if self.store_df is not None:
            source_df = self.store_df
        else:
            # ä»é•¿è¡¨å»é‡è·å–é—¨åº—æ•°æ®
            source_df = self.df.drop_duplicates(subset=['é—¨åº—åç§°'])
        
        circle_stats = source_df.groupby('å•†åœˆç±»å‹').agg({
            'é—¨åº—åç§°': 'count',
            '5kmå†…ç«å¯¹æ•°é‡': 'mean',
            'è¿‘15å¤©5kmå†…æ–°å¢ç«å¯¹æ•°é‡': 'mean'
        }).reset_index()
        
        circle_stats.columns = ['å•†åœˆç±»å‹', 'é—¨åº—æ•°', 'å¹³å‡ç«å¯¹æ•°', 'å¹³å‡æ–°å¢ç«å¯¹æ•°']
        circle_stats['å¹³å‡ç«å¯¹æ•°'] = circle_stats['å¹³å‡ç«å¯¹æ•°'].round(2)
        circle_stats['å¹³å‡æ–°å¢ç«å¯¹æ•°'] = circle_stats['å¹³å‡æ–°å¢ç«å¯¹æ•°'].round(2)
        
        # æŒ‰å•†åœˆç±»å‹æ’åºï¼ˆå¼º > ä¸­ > å¼±ï¼‰
        order = {'å¼º': 0, 'ä¸­': 1, 'å¼±': 2}
        circle_stats['æ’åº'] = circle_stats['å•†åœˆç±»å‹'].map(order)
        circle_stats = circle_stats.sort_values('æ’åº').drop('æ’åº', axis=1)
        
        return circle_stats
    
    def get_region_analysis(self) -> pd.DataFrame:
        """è·å–åŒºåŸŸç±»å‹åˆ†æ
        
        Returns:
            DataFrame: åŒºåŸŸç±»å‹ | é—¨åº—æ•° | ç«å¯¹æ€»æ•° | æ–°å¢ç«å¯¹æ•°
            - ç«å¯¹æ€»æ•°: è¯¥åŒºåŸŸé—¨åº—5kmå†…ç«å¯¹æ•°é‡çš„æ€»å’Œï¼ˆå¯èƒ½æœ‰é‡å¤ï¼‰
            - æ–°å¢ç«å¯¹æ•°: ä»é•¿è¡¨ç»Ÿè®¡çš„å®é™…æ–°å¢ç«å¯¹è®°å½•æ•°ï¼ˆå»é‡åï¼‰
        """
        if 'åŒºåŸŸç±»å‹' not in self.df.columns:
            logger.warning("âš ï¸ æ•°æ®ä¸­æ²¡æœ‰'åŒºåŸŸç±»å‹'åˆ—ï¼Œè¯·å…ˆè¿›è¡ŒåŒºåŸŸåˆ†ç±»")
            return pd.DataFrame()
        
        # ä»é•¿è¡¨ç»Ÿè®¡å®é™…çš„æ–°å¢ç«å¯¹æ•°é‡ï¼ˆæ¯æ¡è®°å½•ä»£è¡¨ä¸€ä¸ªæ–°å¢ç«å¯¹ï¼‰
        region_competitor_count = self.df.groupby('åŒºåŸŸç±»å‹').agg({
            'ç«å¯¹åç§°': 'count'  # ç»Ÿè®¡å®é™…çš„ç«å¯¹è®°å½•æ•°
        }).reset_index()
        region_competitor_count.columns = ['åŒºåŸŸç±»å‹', 'æ–°å¢ç«å¯¹æ•°']
        
        # ç»Ÿè®¡é—¨åº—æ•°
        if self.store_df is not None and 'åŒºåŸŸç±»å‹' in self.store_df.columns:
            region_store_count = self.store_df.groupby('åŒºåŸŸç±»å‹').agg({
                'é—¨åº—åç§°': 'count',
                '5kmå†…ç«å¯¹æ•°é‡': 'sum'
            }).reset_index()
            region_store_count.columns = ['åŒºåŸŸç±»å‹', 'é—¨åº—æ•°', 'ç«å¯¹æ€»æ•°']
        else:
            store_region = self.df.drop_duplicates(subset=['é—¨åº—åç§°'])[['é—¨åº—åç§°', 'åŒºåŸŸç±»å‹', '5kmå†…ç«å¯¹æ•°é‡']]
            region_store_count = store_region.groupby('åŒºåŸŸç±»å‹').agg({
                'é—¨åº—åç§°': 'count',
                '5kmå†…ç«å¯¹æ•°é‡': 'sum'
            }).reset_index()
            region_store_count.columns = ['åŒºåŸŸç±»å‹', 'é—¨åº—æ•°', 'ç«å¯¹æ€»æ•°']
        
        # åˆå¹¶ç»“æœ
        region_stats = region_store_count.merge(region_competitor_count, on='åŒºåŸŸç±»å‹', how='left')
        region_stats['æ–°å¢ç«å¯¹æ•°'] = region_stats['æ–°å¢ç«å¯¹æ•°'].fillna(0).astype(int)
        
        return region_stats
    
    def get_competitor_details(self, filters: dict = None, 
                                sort_by: str = None, 
                                ascending: bool = False) -> pd.DataFrame:
        """è·å–ç«å¯¹è¯¦æƒ…è¡¨
        
        Args:
            filters: ç­›é€‰æ¡ä»¶å­—å…¸
                - city: åŸå¸‚
                - business_circle: å•†åœˆç±»å‹
                - region: åŒºåŸŸç±»å‹
                - brand: å“ç‰Œåç§°
            sort_by: æ’åºå­—æ®µï¼ˆ'SKUæ•°' æˆ– 'å•†è¡¥ç‡'ï¼‰
            ascending: æ˜¯å¦å‡åº
            
        Returns:
            DataFrame: é—¨åº—åç§° | åŸå¸‚ | å•†åœˆç±»å‹ | åŒºåŸŸç±»å‹ | ç«å¯¹åç§° | å“ç‰Œç‰¹æ€§ | SKUæ•° | å•†è¡¥ç‡
        """
        result_df = self.df.copy()
        
        # åº”ç”¨ç­›é€‰æ¡ä»¶
        if filters:
            if filters.get('city'):
                result_df = result_df[result_df['åŸå¸‚'] == filters['city']]
            if filters.get('business_circle'):
                result_df = result_df[result_df['å•†åœˆç±»å‹'] == filters['business_circle']]
            if filters.get('region') and 'åŒºåŸŸç±»å‹' in result_df.columns:
                result_df = result_df[result_df['åŒºåŸŸç±»å‹'] == filters['region']]
            if filters.get('brand'):
                result_df = result_df[result_df['ç«å¯¹åç§°'].str.contains(filters['brand'], na=False)]
        
        # æ’åº
        if sort_by and sort_by in result_df.columns:
            # å¤„ç†å•†è¡¥ç‡æ’åºï¼ˆéœ€è¦è½¬æ¢ä¸ºæ•°å€¼ï¼‰
            if sort_by == 'å•†è¡¥ç‡':
                result_df['å•†è¡¥ç‡æ’åºå€¼'] = result_df['å•†è¡¥ç‡'].apply(self._parse_subsidy_rate)
                result_df = result_df.sort_values('å•†è¡¥ç‡æ’åºå€¼', ascending=ascending)
                result_df = result_df.drop('å•†è¡¥ç‡æ’åºå€¼', axis=1)
            else:
                result_df = result_df.sort_values(sort_by, ascending=ascending)
        
        # é€‰æ‹©å±•ç¤ºåˆ—
        display_cols = ['é—¨åº—åç§°', 'åŸå¸‚', 'å•†åœˆç±»å‹', 'ç«å¯¹åç§°', 'å“ç‰Œç‰¹æ€§', 'SKUæ•°', 'å•†è¡¥ç‡']
        if 'åŒºåŸŸç±»å‹' in result_df.columns:
            display_cols.insert(3, 'åŒºåŸŸç±»å‹')
        
        available_cols = [col for col in display_cols if col in result_df.columns]
        return result_df[available_cols]
    
    def _parse_subsidy_rate(self, rate_str) -> float:
        """è§£æå•†è¡¥ç‡å­—ç¬¦ä¸²ä¸ºæ•°å€¼ï¼ˆç”¨äºæ’åºï¼‰"""
        if pd.isna(rate_str):
            return 0.0
        
        # æå–æ•°å­—ï¼Œå¦‚ "10%-20%" -> 15
        numbers = re.findall(r'\d+', str(rate_str))
        if numbers:
            return sum(float(n) for n in numbers) / len(numbers)
        return 0.0
    
    def extract_brand_keywords(self) -> dict:
        """æå–å“ç‰Œç‰¹æ€§å…³é”®è¯åŠé¢‘æ¬¡
        
        Returns:
            dict: {'å…³é”®è¯': é¢‘æ¬¡, ...}
        """
        # å®šä¹‰å…³é”®è¯åˆ—è¡¨
        keywords = [
            'ä½èµ·é€', 'ä½é—¨æ§›', 'æ–°å®¢', 'ç«‹å‡', 'ç¥åˆ¸', 'ç¥ä»·', 'æ»¡å‡',
            'å•†è¡¥', 'è¡¥è´´', 'æŠ˜æ‰£', 'çˆ†å“', 'æ´»åŠ¨', 'é…é€', 'å…é…',
            'å¼€ä¸š', 'æ”¶è´§', 'è¥é”€', 'æ—¥å‡', 'å•é‡'
        ]
        
        keyword_counts = Counter()
        
        for text in self.df['å“ç‰Œç‰¹æ€§'].dropna():
            text = str(text)
            for keyword in keywords:
                if keyword in text:
                    keyword_counts[keyword] += 1
        
        return dict(keyword_counts.most_common())
    
    def get_overview_stats(self) -> dict:
        """è·å–æ¦‚è§ˆç»Ÿè®¡æ•°æ®"""
        if self.store_df is not None:
            total_stores = len(self.store_df)
            total_competitors = self.store_df['5kmå†…ç«å¯¹æ•°é‡'].sum()
            total_new_competitors = self.store_df['è¿‘15å¤©5kmå†…æ–°å¢ç«å¯¹æ•°é‡'].sum()
            stores_with_new = (self.store_df['è¿‘15å¤©5kmå†…æ–°å¢ç«å¯¹æ•°é‡'] > 0).sum()
        else:
            total_stores = self.df['é—¨åº—åç§°'].nunique()
            total_competitors = self.df.drop_duplicates('é—¨åº—åç§°')['5kmå†…ç«å¯¹æ•°é‡'].sum()
            total_new_competitors = len(self.df)
            stores_with_new = self.df['é—¨åº—åç§°'].nunique()
        
        # è®¡ç®—åŒºåŸŸåˆ†å¸ƒ
        region_dist = {}
        if 'åŒºåŸŸç±»å‹' in self.df.columns:
            region_counts = self.df['åŒºåŸŸç±»å‹'].value_counts()
            total = region_counts.sum()
            for region in ['å¸‚åŒº', 'å¿åŸ']:
                count = region_counts.get(region, 0)
                region_dist[region] = int(count)
                region_dist[f'{region}å æ¯”'] = round(count / total * 100, 1) if total > 0 else 0
        
        # è®¡ç®—å•†åœˆåˆ†å¸ƒ
        circle_dist = {}
        circle_counts = self.df['å•†åœˆç±»å‹'].value_counts()
        total = circle_counts.sum()
        for circle in ['å¼º', 'ä¸­', 'å¼±']:
            count = circle_counts.get(circle, 0)
            circle_dist[circle] = int(count)
            circle_dist[f'{circle}å æ¯”'] = round(count / total * 100, 1) if total > 0 else 0
        
        return {
            'æ€»é—¨åº—æ•°': total_stores,
            '5kmå†…ç«å¯¹æ€»æ•°': int(total_competitors),
            'æ–°å¢ç«å¯¹æ€»æ•°': int(total_new_competitors),
            'æœ‰æ–°å¢ç«å¯¹çš„é—¨åº—æ•°': int(stores_with_new),
            'æ–°å¢ç«å¯¹å“ç‰Œæ•°': self.df['ç«å¯¹åç§°'].nunique() if len(self.df) > 0 else 0,
            'è¦†ç›–åŸå¸‚æ•°': self.df['åŸå¸‚'].nunique() if len(self.df) > 0 else 0,
            'åŒºåŸŸåˆ†å¸ƒ': region_dist,
            'å•†åœˆåˆ†å¸ƒ': circle_dist
        }
    
    def get_circle_region_cross_analysis(self) -> pd.DataFrame:
        """è·å–å•†åœˆç±»å‹Ã—åŒºåŸŸç±»å‹äº¤å‰åˆ†æ
        
        Returns:
            DataFrame: å•†åœˆç±»å‹ | åŒºåŸŸç±»å‹ | é—¨åº—æ•° | å¹³å‡ç«å¯¹æ•° | å¹³å‡æ–°å¢ç«å¯¹æ•°
        """
        if self.store_df is None or 'åŒºåŸŸç±»å‹' not in self.store_df.columns:
            return pd.DataFrame()
        
        cross_stats = self.store_df.groupby(['å•†åœˆç±»å‹', 'åŒºåŸŸç±»å‹']).agg({
            'é—¨åº—åç§°': 'count',
            '5kmå†…ç«å¯¹æ•°é‡': 'mean',
            'è¿‘15å¤©5kmå†…æ–°å¢ç«å¯¹æ•°é‡': 'mean'
        }).reset_index()
        
        cross_stats.columns = ['å•†åœˆç±»å‹', 'åŒºåŸŸç±»å‹', 'é—¨åº—æ•°', 'å¹³å‡ç«å¯¹æ•°', 'å¹³å‡æ–°å¢ç«å¯¹æ•°']
        cross_stats['å¹³å‡ç«å¯¹æ•°'] = cross_stats['å¹³å‡ç«å¯¹æ•°'].round(2)
        cross_stats['å¹³å‡æ–°å¢ç«å¯¹æ•°'] = cross_stats['å¹³å‡æ–°å¢ç«å¯¹æ•°'].round(2)
        
        return cross_stats
    
    def get_region_circle_distribution(self) -> dict:
        """è·å–å¸‚åŒº/å¿åŸçš„å¼ºä¸­å¼±å•†åœˆåˆ†å¸ƒ
        
        Returns:
            dict: {
                'å¸‚åŒº': {'å¼º': count, 'ä¸­': count, 'å¼±': count, 'å¼ºå æ¯”': pct, ...},
                'å¿åŸ': {'å¼º': count, 'ä¸­': count, 'å¼±': count, 'å¼ºå æ¯”': pct, ...}
            }
        """
        if self.store_df is None or 'åŒºåŸŸç±»å‹' not in self.store_df.columns:
            return {}
        
        result = {}
        for region in ['å¸‚åŒº', 'å¿åŸ']:
            region_df = self.store_df[self.store_df['åŒºåŸŸç±»å‹'] == region]
            total = len(region_df)
            if total == 0:
                result[region] = {'å¼º': 0, 'ä¸­': 0, 'å¼±': 0, 'å¼ºå æ¯”': 0, 'ä¸­å æ¯”': 0, 'å¼±å æ¯”': 0}
                continue
            
            circle_counts = region_df['å•†åœˆç±»å‹'].value_counts().to_dict()
            result[region] = {
                'å¼º': circle_counts.get('å¼º', 0),
                'ä¸­': circle_counts.get('ä¸­', 0),
                'å¼±': circle_counts.get('å¼±', 0),
                'å¼ºå æ¯”': round(circle_counts.get('å¼º', 0) / total * 100, 1),
                'ä¸­å æ¯”': round(circle_counts.get('ä¸­', 0) / total * 100, 1),
                'å¼±å æ¯”': round(circle_counts.get('å¼±', 0) / total * 100, 1),
                'æ€»é—¨åº—æ•°': total
            }
        
        return result
    
    def get_new_competitor_circle_distribution(self) -> dict:
        """è·å–å¸‚åŒº/å¿åŸçš„æ–°å¢ç«å¯¹æŒ‰å•†åœˆç±»å‹åˆ†å¸ƒ
        
        ä»é•¿è¡¨ï¼ˆæ¯è¡Œä¸€ä¸ªç«å¯¹è®°å½•ï¼‰ç»Ÿè®¡æ–°å¢ç«å¯¹åœ¨ä¸åŒå•†åœˆçš„åˆ†å¸ƒ
        
        Returns:
            dict: {
                'å¸‚åŒº': {'å¼º': count, 'ä¸­': count, 'å¼±': count, 'å¼ºå æ¯”': pct, ..., 'æ€»æ–°å¢ç«å¯¹æ•°': total},
                'å¿åŸ': {'å¼º': count, 'ä¸­': count, 'å¼±': count, 'å¼ºå æ¯”': pct, ..., 'æ€»æ–°å¢ç«å¯¹æ•°': total}
            }
        """
        if 'åŒºåŸŸç±»å‹' not in self.df.columns or 'å•†åœˆç±»å‹' not in self.df.columns:
            return {}
        
        result = {}
        for region in ['å¸‚åŒº', 'å¿åŸ']:
            region_df = self.df[self.df['åŒºåŸŸç±»å‹'] == region]
            total = len(region_df)
            if total == 0:
                result[region] = {'å¼º': 0, 'ä¸­': 0, 'å¼±': 0, 'å¼ºå æ¯”': 0, 'ä¸­å æ¯”': 0, 'å¼±å æ¯”': 0, 'æ€»æ–°å¢ç«å¯¹æ•°': 0}
                continue
            
            circle_counts = region_df['å•†åœˆç±»å‹'].value_counts().to_dict()
            result[region] = {
                'å¼º': circle_counts.get('å¼º', 0),
                'ä¸­': circle_counts.get('ä¸­', 0),
                'å¼±': circle_counts.get('å¼±', 0),
                'å¼ºå æ¯”': round(circle_counts.get('å¼º', 0) / total * 100, 1),
                'ä¸­å æ¯”': round(circle_counts.get('ä¸­', 0) / total * 100, 1),
                'å¼±å æ¯”': round(circle_counts.get('å¼±', 0) / total * 100, 1),
                'æ€»æ–°å¢ç«å¯¹æ•°': total
            }
        
        return result
    
    def get_competitor_by_city_region(self) -> pd.DataFrame:
        """è·å–5kmç«å¯¹æ•°æŒ‰åŸå¸‚å’ŒåŒºåŸŸç±»å‹åˆ†æ
        
        Returns:
            DataFrame: åŸå¸‚ | åŒºåŸŸç±»å‹ | é—¨åº—æ•° | ç«å¯¹æ€»æ•° | å¹³å‡ç«å¯¹æ•°
        """
        if self.store_df is None or 'åŒºåŸŸç±»å‹' not in self.store_df.columns:
            return pd.DataFrame()
        
        stats = self.store_df.groupby(['åŸå¸‚', 'åŒºåŸŸç±»å‹']).agg({
            'é—¨åº—åç§°': 'count',
            '5kmå†…ç«å¯¹æ•°é‡': ['sum', 'mean']
        }).reset_index()
        
        stats.columns = ['åŸå¸‚', 'åŒºåŸŸç±»å‹', 'é—¨åº—æ•°', 'ç«å¯¹æ€»æ•°', 'å¹³å‡ç«å¯¹æ•°']
        stats['å¹³å‡ç«å¯¹æ•°'] = stats['å¹³å‡ç«å¯¹æ•°'].round(2)
        
        return stats.sort_values(['åŸå¸‚', 'åŒºåŸŸç±»å‹'])
    
    def get_new_competitor_by_city_region(self) -> pd.DataFrame:
        """è·å–æ–°å¢ç«å¯¹æ•°æŒ‰åŸå¸‚å’ŒåŒºåŸŸç±»å‹åˆ†æ
        
        Returns:
            DataFrame: åŸå¸‚ | åŒºåŸŸç±»å‹ | é—¨åº—æ•° | æ–°å¢ç«å¯¹æ€»æ•° | å¹³å‡æ–°å¢ç«å¯¹æ•°
        """
        if self.store_df is None or 'åŒºåŸŸç±»å‹' not in self.store_df.columns:
            return pd.DataFrame()
        
        stats = self.store_df.groupby(['åŸå¸‚', 'åŒºåŸŸç±»å‹']).agg({
            'é—¨åº—åç§°': 'count',
            'è¿‘15å¤©5kmå†…æ–°å¢ç«å¯¹æ•°é‡': ['sum', 'mean']
        }).reset_index()
        
        stats.columns = ['åŸå¸‚', 'åŒºåŸŸç±»å‹', 'é—¨åº—æ•°', 'æ–°å¢ç«å¯¹æ€»æ•°', 'å¹³å‡æ–°å¢ç«å¯¹æ•°']
        stats['å¹³å‡æ–°å¢ç«å¯¹æ•°'] = stats['å¹³å‡æ–°å¢ç«å¯¹æ•°'].round(2)
        
        return stats.sort_values('æ–°å¢ç«å¯¹æ€»æ•°', ascending=False)
    
    def get_region_competitor_distribution(self) -> pd.DataFrame:
        """è·å–åŒºåŸŸç±»å‹çš„ç«å¯¹æ•°åˆ†å¸ƒï¼ˆç”¨äºç®±çº¿å›¾ï¼‰
        
        Returns:
            DataFrame: åŒºåŸŸç±»å‹ | 5kmå†…ç«å¯¹æ•°é‡ï¼ˆæ¯è¡Œä¸€ä¸ªé—¨åº—ï¼‰
        """
        if self.store_df is None or 'åŒºåŸŸç±»å‹' not in self.store_df.columns:
            return pd.DataFrame()
        
        return self.store_df[['åŒºåŸŸç±»å‹', '5kmå†…ç«å¯¹æ•°é‡', 'è¿‘15å¤©5kmå†…æ–°å¢ç«å¯¹æ•°é‡']].copy()

    def get_sku_scale_distribution(self) -> dict:
        """è·å–ç«å¯¹SKUè§„æ¨¡åˆ†å¸ƒ
        
        Returns:
            dict: {'å°å‹(<3000)': count, 'ä¸­å‹(3000-6000)': count, 'å¤§å‹(>6000)': count}
        """
        if 'SKUæ•°' not in self.df.columns:
            return {}
        
        sku_data = self.df['SKUæ•°'].dropna()
        
        small = (sku_data < 3000).sum()
        medium = ((sku_data >= 3000) & (sku_data <= 6000)).sum()
        large = (sku_data > 6000).sum()
        
        return {
            'å°å‹(<3000)': int(small),
            'ä¸­å‹(3000-6000)': int(medium),
            'å¤§å‹(>6000)': int(large)
        }
    
    def get_subsidy_distribution(self) -> dict:
        """è·å–å•†è¡¥ç‡åˆ†å¸ƒ
        
        Returns:
            dict: {'æ— å•†è¡¥': count, '10%-20%': count, '20%-30%': count, '>30%': count}
        """
        if 'å•†è¡¥ç‡' not in self.df.columns:
            return {}
        
        result = {
            'æ— å•†è¡¥': 0,
            '10%-20%': 0,
            '20%-30%': 0,
            '>30%': 0
        }
        
        for _, row in self.df.iterrows():
            val = row.get('å•†è¡¥ç‡')
            if pd.isna(val):
                result['æ— å•†è¡¥'] += 1
                continue
            val = str(val).lower().strip()
            if val in ['nan', '', 'æ— ', '-']:
                result['æ— å•†è¡¥'] += 1
            elif '10%' in val or '10-20' in val or '10%-20%' in val:
                result['10%-20%'] += 1
            elif '20%' in val or '20-30' in val or '20%-30%' in val:
                result['20%-30%'] += 1
            elif '30%' in val or '>30' in val:
                result['>30%'] += 1
            else:
                result['æ— å•†è¡¥'] += 1
        
        return result
    
    def get_subsidy_brand_detail(self) -> pd.DataFrame:
        """è·å–å„å•†è¡¥ç‡æ¡£ä½çš„å“ç‰Œè¯¦æƒ…
        
        Returns:
            DataFrame: å•†è¡¥ç‡æ¡£ä½ | å“ç‰Œ | æ•°é‡
        """
        if 'å•†è¡¥ç‡' not in self.df.columns:
            return pd.DataFrame()
        
        records = []
        for _, row in self.df.iterrows():
            val = row.get('å•†è¡¥ç‡')
            brand = row.get('ç«å¯¹åç§°', 'æœªçŸ¥')
            
            if pd.isna(val):
                level = 'æ— å•†è¡¥'
            else:
                val = str(val).lower().strip()
                if val in ['nan', '', 'æ— ', '-']:
                    level = 'æ— å•†è¡¥'
                elif '10%' in val or '10-20' in val:
                    level = '10%-20%'
                elif '20%' in val or '20-30' in val:
                    level = '20%-30%'
                elif '30%' in val or '>30' in val:
                    level = '>30%'
                else:
                    level = 'æ— å•†è¡¥'
            
            records.append({'å•†è¡¥ç‡æ¡£ä½': level, 'å“ç‰Œ': brand})
        
        df = pd.DataFrame(records)
        result = df.groupby(['å•†è¡¥ç‡æ¡£ä½', 'å“ç‰Œ']).size().reset_index(name='æ•°é‡')
        return result.sort_values(['å•†è¡¥ç‡æ¡£ä½', 'æ•°é‡'], ascending=[True, False])
    
    def get_brand_city_heatmap(self) -> pd.DataFrame:
        """è·å–å“ç‰ŒÃ—åŸå¸‚çƒ­åŠ›å›¾æ•°æ®
        
        Returns:
            DataFrame: å“ç‰Œ | åŸå¸‚ | æ•°é‡ï¼ˆé€è§†è¡¨æ ¼å¼ï¼‰
        """
        if len(self.df) == 0:
            return pd.DataFrame()
        
        # ç»Ÿè®¡å“ç‰Œåœ¨å„åŸå¸‚çš„å‡ºç°æ¬¡æ•°
        brand_city = self.df.groupby(['ç«å¯¹åç§°', 'åŸå¸‚']).size().reset_index(name='æ•°é‡')
        
        # åªå–TOP10å“ç‰Œ
        top_brands = self.df['ç«å¯¹åç§°'].value_counts().head(10).index.tolist()
        brand_city = brand_city[brand_city['ç«å¯¹åç§°'].isin(top_brands)]
        
        # é€è§†è¡¨
        pivot = brand_city.pivot_table(index='ç«å¯¹åç§°', columns='åŸå¸‚', values='æ•°é‡', fill_value=0)
        
        return pivot
    
    def get_new_competitor_by_city(self) -> pd.DataFrame:
        """è·å–è¿‘15å¤©æ–°å¢ç«å¯¹æŒ‰åŸå¸‚åˆ†å¸ƒ
        
        Returns:
            DataFrame: åŸå¸‚ | é—¨åº—æ•° | æœ‰æ–°å¢çš„é—¨åº—æ•° | æ–°å¢ç«å¯¹æ€»æ•° | å¹³å‡æ–°å¢æ•°
        """
        if self.store_df is None:
            return pd.DataFrame()
        
        stats = self.store_df.groupby('åŸå¸‚').agg({
            'é—¨åº—åç§°': 'count',
            'è¿‘15å¤©5kmå†…æ–°å¢ç«å¯¹æ•°é‡': ['sum', 'mean', lambda x: (x > 0).sum()]
        }).reset_index()
        
        stats.columns = ['åŸå¸‚', 'é—¨åº—æ•°', 'æ–°å¢ç«å¯¹æ€»æ•°', 'å¹³å‡æ–°å¢æ•°', 'æœ‰æ–°å¢çš„é—¨åº—æ•°']
        stats['å¹³å‡æ–°å¢æ•°'] = stats['å¹³å‡æ–°å¢æ•°'].round(2)
        stats['æ–°å¢å æ¯”'] = (stats['æœ‰æ–°å¢çš„é—¨åº—æ•°'] / stats['é—¨åº—æ•°'] * 100).round(1)
        
        return stats.sort_values('æ–°å¢ç«å¯¹æ€»æ•°', ascending=False)

    def get_brand_region_expansion(self) -> pd.DataFrame:
        """è·å–å“ç‰Œåœ¨å¸‚åŒº/å¿åŸçš„æ‰©å¼ è¶‹åŠ¿å¯¹æ¯”
        
        Returns:
            DataFrame: å“ç‰Œåç§° | å¸‚åŒºæ•°é‡ | å¿åŸæ•°é‡ | æ€»æ•° | å¸‚åŒºå æ¯” | å¿åŸå æ¯” | æ‰©å¼ å€¾å‘
        """
        if 'åŒºåŸŸç±»å‹' not in self.df.columns:
            return pd.DataFrame()
        
        # ç»Ÿè®¡æ¯ä¸ªå“ç‰Œåœ¨å¸‚åŒºå’Œå¿åŸçš„æ•°é‡
        brand_region = self.df.groupby(['ç«å¯¹åç§°', 'åŒºåŸŸç±»å‹']).size().unstack(fill_value=0)
        
        # ç¡®ä¿æœ‰å¸‚åŒºå’Œå¿åŸåˆ—
        if 'å¸‚åŒº' not in brand_region.columns:
            brand_region['å¸‚åŒº'] = 0
        if 'å¿åŸ' not in brand_region.columns:
            brand_region['å¿åŸ'] = 0
        
        brand_region = brand_region.reset_index()
        brand_region.columns = ['å“ç‰Œåç§°', 'å¿åŸæ•°é‡', 'å¸‚åŒºæ•°é‡'] if brand_region.columns[1] == 'å¿åŸ' else ['å“ç‰Œåç§°', 'å¸‚åŒºæ•°é‡', 'å¿åŸæ•°é‡']
        
        # é‡æ–°æ’åˆ—åˆ—é¡ºåº
        if 'å¸‚åŒºæ•°é‡' in brand_region.columns and 'å¿åŸæ•°é‡' in brand_region.columns:
            brand_region = brand_region[['å“ç‰Œåç§°', 'å¸‚åŒºæ•°é‡', 'å¿åŸæ•°é‡']]
        
        brand_region['æ€»æ•°'] = brand_region['å¸‚åŒºæ•°é‡'] + brand_region['å¿åŸæ•°é‡']
        brand_region['å¸‚åŒºå æ¯”'] = (brand_region['å¸‚åŒºæ•°é‡'] / brand_region['æ€»æ•°'] * 100).round(1)
        brand_region['å¿åŸå æ¯”'] = (brand_region['å¿åŸæ•°é‡'] / brand_region['æ€»æ•°'] * 100).round(1)
        
        # åˆ¤æ–­æ‰©å¼ å€¾å‘
        def get_tendency(row):
            if row['å¸‚åŒºå æ¯”'] > 60:
                return 'å¸‚åŒºä¸ºä¸»'
            elif row['å¿åŸå æ¯”'] > 60:
                return 'å¿åŸä¸ºä¸»'
            else:
                return 'å‡è¡¡å‘å±•'
        
        brand_region['æ‰©å¼ å€¾å‘'] = brand_region.apply(get_tendency, axis=1)
        
        # æŒ‰æ€»æ•°æ’åº
        return brand_region.sort_values('æ€»æ•°', ascending=False)

    def generate_insights(self) -> dict:
        """ç”Ÿæˆç«å¯¹åˆ†ææ´å¯ŸæŠ¥å‘Š
        
        Returns:
            dict: {
                'summary': æ€»ä½“æ¦‚è¿°,
                'key_findings': [å…³é”®å‘ç°åˆ—è¡¨],
                'risk_alerts': [é£é™©é¢„è­¦åˆ—è¡¨],
                'recommendations': [å»ºè®®åˆ—è¡¨]
            }
        """
        insights = {
            'summary': '',
            'key_findings': [],
            'risk_alerts': [],
            'recommendations': []
        }
        
        # è·å–åŸºç¡€ç»Ÿè®¡æ•°æ®
        stats = self.get_overview_stats()
        city_summary = self.get_city_summary()
        brand_ranking = self.get_brand_ranking(top_n=10)
        region_stats = self.get_region_analysis()
        
        total_stores = stats.get('æ€»é—¨åº—æ•°', 0)
        total_new_competitors = stats.get('æ–°å¢ç«å¯¹æ€»æ•°', 0)
        stores_with_new = stats.get('æœ‰æ–°å¢ç«å¯¹çš„é—¨åº—æ•°', 0)
        total_brands = stats.get('æ–°å¢ç«å¯¹å“ç‰Œæ•°', 0)
        
        # 1. æ€»ä½“æ¦‚è¿°
        if total_stores > 0:
            affected_rate = round(stores_with_new / total_stores * 100, 1)
            
            # è®¡ç®—å—å½±å“é—¨åº—çš„å¹³å‡æ–°å¢æ•°å’Œæœ€é«˜æ–°å¢æ•°
            max_new = 0
            avg_affected = 0
            if self.store_df is not None and 'è¿‘15å¤©5kmå†…æ–°å¢ç«å¯¹æ•°é‡' in self.store_df.columns:
                affected_stores = self.store_df[self.store_df['è¿‘15å¤©5kmå†…æ–°å¢ç«å¯¹æ•°é‡'] > 0]
                if len(affected_stores) > 0:
                    max_new = int(affected_stores['è¿‘15å¤©5kmå†…æ–°å¢ç«å¯¹æ•°é‡'].max())
                    avg_affected = round(affected_stores['è¿‘15å¤©5kmå†…æ–°å¢ç«å¯¹æ•°é‡'].mean(), 1)
            
            insights['summary'] = f"è¿‘15å¤©å†…ï¼Œ{total_stores}å®¶é—¨åº—ä¸­æœ‰{stores_with_new}å®¶({affected_rate}%)å‘¨è¾¹å‡ºç°æ–°å¢ç«å¯¹ï¼Œå…±è®¡{total_new_competitors}å®¶æ–°ç«å¯¹ï¼Œæ¶‰åŠ{total_brands}ä¸ªå“ç‰Œã€‚å—å½±å“é—¨åº—å¹³å‡æ–°å¢{avg_affected}ä¸ªç«å¯¹ï¼Œå•åº—æœ€é«˜æ–°å¢{max_new}ä¸ªã€‚"
        
        # 2. å…³é”®å‘ç°
        # 2.1 åŸå¸‚ç»´åº¦åˆ†æ
        if not city_summary.empty:
            top_city = city_summary.iloc[0]
            insights['key_findings'].append(
                f"ğŸ™ï¸ ç«äº‰æœ€æ¿€çƒˆåŸå¸‚ï¼š{top_city['åŸå¸‚']}ï¼Œæ–°å¢{int(top_city['æ–°å¢ç«å¯¹æ•°'])}å®¶ç«å¯¹ï¼Œå æ€»æ–°å¢çš„{top_city['å æ¯”']}%"
            )
            
            # æ‰¾å‡ºæ–°å¢ç«å¯¹æ•°è¶…è¿‡å¹³å‡å€¼2å€çš„åŸå¸‚
            if len(city_summary) > 1:
                avg_new = city_summary['æ–°å¢ç«å¯¹æ•°'].mean()
                hot_cities = city_summary[city_summary['æ–°å¢ç«å¯¹æ•°'] > avg_new * 1.5]
                if len(hot_cities) > 1:
                    hot_city_names = hot_cities['åŸå¸‚'].tolist()[:3]
                    insights['key_findings'].append(
                        f"ğŸ”¥ ç«äº‰çƒ­ç‚¹åŸå¸‚ï¼š{', '.join(hot_city_names)}ï¼Œæ–°å¢ç«å¯¹æ•°æ˜¾è‘—é«˜äºå¹³å‡æ°´å¹³"
                    )
        
        # 2.2 å“ç‰Œç»´åº¦åˆ†æ
        if not brand_ranking.empty:
            top_brand = brand_ranking.iloc[0]
            insights['key_findings'].append(
                f"ğŸ† æ‰©å¼ æœ€å¿«å“ç‰Œï¼š{top_brand['å“ç‰Œåç§°']}ï¼Œæ–°å¢{int(top_brand['å‡ºç°æ¬¡æ•°'])}å®¶é—¨åº—ï¼Œå æ¯”{top_brand['å æ¯”']}%"
            )
            
            # åˆ†æå“ç‰Œé›†ä¸­åº¦
            if len(brand_ranking) >= 3:
                top3_share = brand_ranking.head(3)['å æ¯”'].sum()
                if top3_share > 50:
                    insights['key_findings'].append(
                        f"ğŸ“Š å“ç‰Œé›†ä¸­åº¦é«˜ï¼šTOP3å“ç‰Œå æ–°å¢ç«å¯¹çš„{round(top3_share, 1)}%ï¼Œå¸‚åœºç«äº‰æ ¼å±€ç›¸å¯¹é›†ä¸­"
                    )
        
        # 2.3 åŒºåŸŸç»´åº¦åˆ†æ
        if not region_stats.empty and 'åŒºåŸŸç±»å‹' in region_stats.columns:
            urban = region_stats[region_stats['åŒºåŸŸç±»å‹'] == 'å¸‚åŒº']
            county = region_stats[region_stats['åŒºåŸŸç±»å‹'] == 'å¿åŸ']
            
            if not urban.empty and not county.empty:
                urban_new = urban['æ–°å¢ç«å¯¹æ•°'].values[0] if 'æ–°å¢ç«å¯¹æ•°' in urban.columns else 0
                county_new = county['æ–°å¢ç«å¯¹æ•°'].values[0] if 'æ–°å¢ç«å¯¹æ•°' in county.columns else 0
                total_new = urban_new + county_new
                
                if total_new > 0:
                    urban_pct = round(urban_new / total_new * 100, 1)
                    county_pct = round(county_new / total_new * 100, 1)
                    
                    if urban_pct > 60:
                        insights['key_findings'].append(
                            f"ğŸ“ å¸‚åŒºç«äº‰åŠ å‰§ï¼š{urban_pct}%çš„æ–°å¢ç«å¯¹å‡ºç°åœ¨å¸‚åŒºï¼Œå¸‚åŒºé—¨åº—é¢ä¸´æ›´å¤§ç«äº‰å‹åŠ›"
                        )
                    elif county_pct > 60:
                        insights['key_findings'].append(
                            f"ğŸ“ å¿åŸç«äº‰åŠ å‰§ï¼š{county_pct}%çš„æ–°å¢ç«å¯¹å‡ºç°åœ¨å¿åŸï¼Œä¸‹æ²‰å¸‚åœºç«äº‰å‡æ¸©"
                        )
                    else:
                        insights['key_findings'].append(
                            f"ğŸ“ åŒºåŸŸç«äº‰å‡è¡¡ï¼šå¸‚åŒº{urban_pct}% vs å¿åŸ{county_pct}%ï¼Œç«äº‰å‹åŠ›åˆ†å¸ƒç›¸å¯¹å‡åŒ€"
                        )
        
        # 3. é£é™©é¢„è­¦
        # 3.1 é«˜ç«äº‰é—¨åº—é¢„è­¦
        if self.store_df is not None and 'è¿‘15å¤©5kmå†…æ–°å¢ç«å¯¹æ•°é‡' in self.store_df.columns:
            high_risk_stores = self.store_df[self.store_df['è¿‘15å¤©5kmå†…æ–°å¢ç«å¯¹æ•°é‡'] >= 3]
            if len(high_risk_stores) > 0:
                insights['risk_alerts'].append(
                    f"âš ï¸ é«˜é£é™©é—¨åº—ï¼š{len(high_risk_stores)}å®¶é—¨åº—å‘¨è¾¹æ–°å¢3ä¸ªåŠä»¥ä¸Šç«å¯¹ï¼Œéœ€é‡ç‚¹å…³æ³¨"
                )
                
                # åˆ—å‡ºTOP3é«˜é£é™©é—¨åº—
                top_risk = high_risk_stores.nlargest(3, 'è¿‘15å¤©5kmå†…æ–°å¢ç«å¯¹æ•°é‡')
                risk_names = top_risk['é—¨åº—åç§°'].tolist()
                insights['risk_alerts'].append(
                    f"ğŸš¨ é‡ç‚¹å…³æ³¨é—¨åº—ï¼š{', '.join(risk_names)}"
                )
        
        # 3.2 å“ç‰Œæ‰©å¼ é¢„è­¦
        if not brand_ranking.empty and len(brand_ranking) >= 1:
            fast_brands = brand_ranking[brand_ranking['å‡ºç°æ¬¡æ•°'] >= 5]
            if len(fast_brands) > 0:
                brand_names = fast_brands['å“ç‰Œåç§°'].tolist()[:3]
                insights['risk_alerts'].append(
                    f"âš¡ å¿«é€Ÿæ‰©å¼ å“ç‰Œï¼š{', '.join(brand_names)}ï¼Œæ‰©å¼ é€Ÿåº¦è¾ƒå¿«ï¼Œéœ€å¯†åˆ‡å…³æ³¨å…¶åŠ¨æ€"
                )
        
        # 4. å»ºè®®
        if total_new_competitors > 0:
            insights['recommendations'].append(
                "ğŸ’¡ å»ºè®®å¯¹é«˜é£é™©é—¨åº—è¿›è¡Œç«å“è°ƒç ”ï¼Œäº†è§£æ–°ç«å¯¹çš„å®šä»·ç­–ç•¥å’Œä¿ƒé”€æ´»åŠ¨"
            )
            
            if stores_with_new / total_stores > 0.3 if total_stores > 0 else False:
                insights['recommendations'].append(
                    "ğŸ’¡ è¶…è¿‡30%é—¨åº—å—åˆ°æ–°ç«å¯¹å½±å“ï¼Œå»ºè®®åˆ¶å®šåŒºåŸŸæ€§ç«äº‰åº”å¯¹ç­–ç•¥"
                )
            
            if not brand_ranking.empty:
                top_brand = brand_ranking.iloc[0]['å“ç‰Œåç§°']
                insights['recommendations'].append(
                    f"ğŸ’¡ é‡ç‚¹ç ”ç©¶{top_brand}çš„å•†ä¸šæ¨¡å¼å’Œç«äº‰ä¼˜åŠ¿ï¼Œåˆ¶å®šé’ˆå¯¹æ€§åº”å¯¹æ–¹æ¡ˆ"
                )
        
        return insights
