"""
P1ä¼˜åŒ–ï¼šæ ¸å¿ƒè®¡ç®—é€»è¾‘å•å…ƒæµ‹è¯•
è¦†ç›–ï¼šKPIè®¡ç®—ã€å¤šè§„æ ¼è¯†åˆ«ã€æ•°æ®åŠ è½½ã€ç¼“å­˜æœºåˆ¶
"""
import unittest
import pandas as pd
import numpy as np
import os
import tempfile
from datetime import datetime
from dashboard_v2 import DataLoader, DataCache, DashboardComponents

class TestDataCache(unittest.TestCase):
    """æµ‹è¯•æ•°æ®ç¼“å­˜æœºåˆ¶"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.test_cache_dir = tempfile.mkdtemp()
        self.cache = DataCache(self.test_cache_dir)
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        import shutil
        if os.path.exists(self.test_cache_dir):
            shutil.rmtree(self.test_cache_dir)
    
    def test_cache_path_generation(self):
        """æµ‹è¯•ç¼“å­˜è·¯å¾„ç”Ÿæˆ"""
        # åˆ›å»ºä¸´æ—¶æµ‹è¯•æ–‡ä»¶
        test_file1 = os.path.join(self.test_cache_dir, "test1.xlsx")
        test_file2 = os.path.join(self.test_cache_dir, "test2.xlsx")
        
        # åˆ›å»ºæ–‡ä»¶
        with open(test_file1, 'wb') as f:
            f.write(b'test content 1')
        with open(test_file2, 'wb') as f:
            f.write(b'test content 2')
        
        path1 = self.cache._get_cache_path(test_file1)
        path2 = self.cache._get_cache_path(test_file1)
        path3 = self.cache._get_cache_path(test_file2)
        
        self.assertEqual(path1, path2, "ç›¸åŒæ–‡ä»¶åº”ç”Ÿæˆç›¸åŒç¼“å­˜è·¯å¾„")
        self.assertNotEqual(path1, path3, "ä¸åŒæ–‡ä»¶åº”ç”Ÿæˆä¸åŒç¼“å­˜è·¯å¾„")
        self.assertTrue(str(path1).endswith('.cache'), "ç¼“å­˜è·¯å¾„åº”ä»¥.cacheç»“å°¾")
    
    def test_cache_set_and_get(self):
        """æµ‹è¯•ç¼“å­˜ä¿å­˜å’ŒåŠ è½½"""
        # åˆ›å»ºä¸´æ—¶æµ‹è¯•æ–‡ä»¶
        test_file = os.path.join(self.test_cache_dir, "test.xlsx")
        with open(test_file, 'wb') as f:
            f.write(b'test content')
        
        test_data = {
            'kpi': pd.DataFrame({'col1': [1, 2, 3]}),
            'category': pd.DataFrame({'col2': ['a', 'b', 'c']})
        }
        
        # ä¿å­˜ç¼“å­˜
        self.cache.set(test_file, test_data)
        cache_path = self.cache._get_cache_path(test_file)
        self.assertTrue(os.path.exists(cache_path), "ç¼“å­˜æ–‡ä»¶åº”è¯¥è¢«åˆ›å»º")
        
        # åŠ è½½ç¼“å­˜
        loaded_data = self.cache.get(test_file)
        self.assertIsNotNone(loaded_data, "åº”è¯¥èƒ½åŠ è½½ç¼“å­˜æ•°æ®")
        self.assertIn('kpi', loaded_data, "ç¼“å­˜åº”åŒ…å«kpiæ•°æ®")
        self.assertIn('category', loaded_data, "ç¼“å­˜åº”åŒ…å«categoryæ•°æ®")
        
        # éªŒè¯æ•°æ®ä¸€è‡´æ€§
        pd.testing.assert_frame_equal(test_data['kpi'], loaded_data['kpi'])
        pd.testing.assert_frame_equal(test_data['category'], loaded_data['category'])
    
    def test_cache_invalidation(self):
        """æµ‹è¯•ç¼“å­˜å¤±æ•ˆæœºåˆ¶"""
        # åˆ›å»ºä¸´æ—¶æµ‹è¯•æ–‡ä»¶
        test_file = os.path.join(self.test_cache_dir, "test.xlsx")
        with open(test_file, 'wb') as f:
            f.write(b'test content')
        
        test_data = {'kpi': pd.DataFrame({'col1': [1, 2, 3]})}
        
        # ä¿å­˜ç¼“å­˜
        self.cache.set(test_file, test_data)
        
        # æ¸…é™¤ç¼“å­˜
        cleared = self.cache.clear()
        self.assertGreater(cleared, 0, "åº”è¯¥æ¸…é™¤äº†è‡³å°‘ä¸€ä¸ªç¼“å­˜æ–‡ä»¶")
        
        # éªŒè¯ç¼“å­˜å·²è¢«æ¸…é™¤
        loaded = self.cache.get(test_file)
        self.assertIsNone(loaded, "æ¸…é™¤åä¸åº”è¯¥èƒ½åŠ è½½ç¼“å­˜")


class TestKPICalculation(unittest.TestCase):
    """æµ‹è¯•KPIè®¡ç®—é€»è¾‘"""
    
    def test_kpi_summary_basic(self):
        """æµ‹è¯•åŸºæœ¬KPIæ±‡æ€»"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        kpi_df = pd.DataFrame({
            'é—¨åº—': ['æµ‹è¯•é—¨åº—'],
            'æ€»SKUæ•°(å«è§„æ ¼)': [1000],
            'å•è§„æ ¼SPUæ•°': [500],
            'å•è§„æ ¼SKUæ•°': [500],
            'å¤šè§„æ ¼SKUæ€»æ•°': [500],
            'æ€»SKUæ•°(å»é‡å)': [800],
            'åŠ¨é”€SKUæ•°': [600],
            'æ»é”€SKUæ•°': [200],
            'æ€»é”€å”®é¢(å»é‡å)': [100000],
            'åŠ¨é”€ç‡': [0.75],
            'å”¯ä¸€å¤šè§„æ ¼å•†å“æ•°': [100]
        })
        
        # æ¨¡æ‹ŸDataLoaderçš„KPIæå–é€»è¾‘
        summary = {}
        row = kpi_df.iloc[0]
        for i, col in enumerate(kpi_df.columns):
            value = row.iloc[i] if i < len(row) else 0
            if i == 0:
                summary['é—¨åº—'] = value
            elif i == 1:
                summary['æ€»SKUæ•°(å«è§„æ ¼)'] = value
            elif i == 5:
                summary['æ€»SKUæ•°(å»é‡å)'] = value
            elif i == 6:
                summary['åŠ¨é”€SKUæ•°'] = value
            elif i == 7:
                summary['æ»é”€SKUæ•°'] = value
            elif i == 9:
                summary['åŠ¨é”€ç‡'] = value
        
        # éªŒè¯ç»“æœ
        self.assertEqual(summary['æ€»SKUæ•°(å«è§„æ ¼)'], 1000)
        self.assertEqual(summary['æ€»SKUæ•°(å»é‡å)'], 800)
        self.assertEqual(summary['åŠ¨é”€SKUæ•°'], 600)
        self.assertEqual(summary['æ»é”€SKUæ•°'], 200)
        self.assertEqual(summary['åŠ¨é”€ç‡'], 0.75)
    
    def test_kpi_edge_cases(self):
        """æµ‹è¯•KPIè®¡ç®—è¾¹ç•Œæƒ…å†µ"""
        # æµ‹è¯•é›¶å€¼
        kpi_df = pd.DataFrame({
            'é—¨åº—': ['ç©ºé—¨åº—'],
            'æ€»SKUæ•°(å«è§„æ ¼)': [0],
            'åŠ¨é”€SKUæ•°': [0],
            'æ€»é”€å”®é¢(å»é‡å)': [0]
        })
        
        row = kpi_df.iloc[0]
        self.assertEqual(row['æ€»SKUæ•°(å«è§„æ ¼)'], 0)
        self.assertEqual(row['åŠ¨é”€SKUæ•°'], 0)
        
        # æµ‹è¯•åŠ¨é”€ç‡è®¡ç®—
        total_sku = 100
        active_sku = 75
        rate = active_sku / total_sku if total_sku > 0 else 0
        self.assertEqual(rate, 0.75)
        
        # æµ‹è¯•é™¤é›¶ä¿æŠ¤
        total_sku = 0
        rate = active_sku / total_sku if total_sku > 0 else 0
        self.assertEqual(rate, 0)


class TestMultispecRecognition(unittest.TestCase):
    """æµ‹è¯•å¤šè§„æ ¼è¯†åˆ«ç®—æ³•"""
    
    def test_multispec_insights_basic(self):
        """æµ‹è¯•åŸºæœ¬å¤šè§„æ ¼æ´å¯Ÿç”Ÿæˆ"""
        category_data = pd.DataFrame({
            'åˆ†ç±»': ['é«˜å¤šè§„æ ¼', 'ä½å¤šè§„æ ¼', 'ä¸­ç­‰å¤šè§„æ ¼'],
            'æ€»SKUæ•°': [100, 100, 100],
            'å¤šè§„æ ¼SKUæ•°': [60, 10, 30]  # 60%, 10%, 30%
        })
        
        insights = DashboardComponents.generate_multispec_insights(category_data)
        
        # éªŒè¯æ´å¯Ÿæ•°é‡
        self.assertGreater(len(insights), 0, "åº”è¯¥ç”Ÿæˆè‡³å°‘ä¸€æ¡æ´å¯Ÿ")
        
        # éªŒè¯åŒ…å«æ•´ä½“ç»Ÿè®¡
        insight_texts = [i['text'] for i in insights]
        has_overall = any('é—¨åº—æ•´ä½“å¤šè§„æ ¼å æ¯”' in text for text in insight_texts)
        self.assertTrue(has_overall, "åº”è¯¥åŒ…å«æ•´ä½“ç»Ÿè®¡æ´å¯Ÿ")
        
        # éªŒè¯åˆ†ç±»è¯†åˆ«
        has_high = any('é«˜å¤šè§„æ ¼å“ç±»' in text and '>50%' in text for text in insight_texts)
        has_low = any('ä½å¤šè§„æ ¼å“ç±»' in text and '<15%' in text for text in insight_texts)
        has_mid = any('ä¸­ç­‰å¤šè§„æ ¼å“ç±»' in text and '20-40%' in text for text in insight_texts)
        
        self.assertTrue(has_high, "åº”è¯¥è¯†åˆ«é«˜å¤šè§„æ ¼å“ç±»")
        self.assertTrue(has_low, "åº”è¯¥è¯†åˆ«ä½å¤šè§„æ ¼å“ç±»")
        self.assertTrue(has_mid, "åº”è¯¥è¯†åˆ«ä¸­ç­‰å¤šè§„æ ¼å“ç±»")
    
    def test_multispec_calculation_accuracy(self):
        """æµ‹è¯•å¤šè§„æ ¼å æ¯”è®¡ç®—å‡†ç¡®æ€§"""
        category_data = pd.DataFrame({
            'åˆ†ç±»': ['åˆ†ç±»A', 'åˆ†ç±»B', 'åˆ†ç±»C'],
            'æ€»SKUæ•°': [100, 200, 300],
            'å¤šè§„æ ¼SKUæ•°': [25, 50, 75]  # 25%, 25%, 25%
        })
        
        insights = DashboardComponents.generate_multispec_insights(category_data)
        
        # æå–æ•´ä½“å æ¯”
        overall_text = [i['text'] for i in insights if 'é—¨åº—æ•´ä½“å¤šè§„æ ¼å æ¯”' in i['text']][0]
        
        # æ‰‹åŠ¨è®¡ç®—éªŒè¯
        total_multi = 25 + 50 + 75  # 150
        total_all = 100 + 200 + 300  # 600
        expected_ratio = total_multi / total_all  # 25%
        
        self.assertIn(f"{expected_ratio:.1%}", overall_text, "æ•´ä½“å æ¯”åº”è¯¥æ­£ç¡®")
        self.assertIn("150", overall_text, "å¤šè§„æ ¼SKUæ•°åº”è¯¥æ­£ç¡®")
        self.assertIn("600", overall_text, "æ€»SKUæ•°åº”è¯¥æ­£ç¡®")
    
    def test_multispec_empty_data(self):
        """æµ‹è¯•ç©ºæ•°æ®å¤„ç†"""
        empty_data = pd.DataFrame()
        insights = DashboardComponents.generate_multispec_insights(empty_data)
        self.assertEqual(len(insights), 0, "ç©ºæ•°æ®åº”è¿”å›ç©ºæ´å¯Ÿåˆ—è¡¨")
    
    def test_multispec_zero_division(self):
        """æµ‹è¯•é™¤é›¶ä¿æŠ¤"""
        category_data = pd.DataFrame({
            'åˆ†ç±»': ['é›¶SKUåˆ†ç±»'],
            'æ€»SKUæ•°': [0],
            'å¤šè§„æ ¼SKUæ•°': [0]
        })
        
        # åº”è¯¥ä¸æŠ›å‡ºå¼‚å¸¸
        try:
            insights = DashboardComponents.generate_multispec_insights(category_data)
            self.assertIsInstance(insights, list, "åº”è¯¥è¿”å›åˆ—è¡¨")
        except ZeroDivisionError:
            self.fail("ä¸åº”è¯¥å‡ºç°é™¤é›¶é”™è¯¯")
    
    def test_multispec_performance(self):
        """æµ‹è¯•å¤§æ•°æ®é‡æ€§èƒ½"""
        import time
        
        # ç”Ÿæˆå¤§æ•°æ®é›†
        n = 1000
        category_data = pd.DataFrame({
            'åˆ†ç±»': [f'åˆ†ç±»{i}' for i in range(n)],
            'æ€»SKUæ•°': np.random.randint(50, 500, n),
            'å¤šè§„æ ¼SKUæ•°': np.random.randint(10, 200, n)
        })
        
        # æ€§èƒ½æµ‹è¯•
        start = time.perf_counter()
        insights = DashboardComponents.generate_multispec_insights(category_data)
        elapsed = time.perf_counter() - start
        
        self.assertLess(elapsed, 0.01, "1000ä¸ªåˆ†ç±»åº”åœ¨10mså†…å®Œæˆ")
        self.assertGreater(len(insights), 0, "åº”è¯¥ç”Ÿæˆæ´å¯Ÿ")


class TestDataLoaderColumnMapping(unittest.TestCase):
    """æµ‹è¯•åˆ—åæ˜ å°„åŠŸèƒ½"""
    
    def test_column_search_logic(self):
        """æµ‹è¯•åˆ—åæœç´¢é€»è¾‘"""
        df = pd.DataFrame({
            'ç¾å›¢ä¸€çº§åˆ†ç±»çˆ†å“skuæ•°': [10, 20, 30],
            'ç¾å›¢ä¸€çº§åˆ†ç±»æŠ˜æ‰£': [0.8, 0.9, 0.85],
            'å…¶ä»–åˆ—': [1, 2, 3]
        })
        
        # æµ‹è¯•åˆ—ååŒ…å«å…³é”®å­—çš„æœç´¢
        keywords = ['çˆ†å“', 'æŠ˜æ‰£']
        found_cols = [col for col in df.columns if any(kw in col for kw in keywords)]
        
        self.assertEqual(len(found_cols), 2, "åº”è¯¥æ‰¾åˆ°2ä¸ªåŒ¹é…åˆ—")
        self.assertIn('ç¾å›¢ä¸€çº§åˆ†ç±»çˆ†å“skuæ•°', found_cols)
        self.assertIn('ç¾å›¢ä¸€çº§åˆ†ç±»æŠ˜æ‰£', found_cols)
    
    def test_column_not_found(self):
        """æµ‹è¯•æ‰¾ä¸åˆ°åˆ—çš„æƒ…å†µ"""
        df = pd.DataFrame({'åˆ—A': [1, 2, 3]})
        
        # æµ‹è¯•ä¸å­˜åœ¨çš„å…³é”®å­—
        keyword = 'ä¸å­˜åœ¨çš„åˆ—'
        found_cols = [col for col in df.columns if keyword in col]
        
        self.assertEqual(len(found_cols), 0, "ä¸åº”è¯¥æ‰¾åˆ°ä»»ä½•åˆ—")
    
    def test_safe_column_access(self):
        """æµ‹è¯•å®‰å…¨çš„åˆ—è®¿é—®"""
        df = pd.DataFrame({
            'ç¾å›¢ä¸€çº§åˆ†ç±»çˆ†å“skuæ•°': [10, 20, 30]
        })
        
        # æµ‹è¯•æˆåŠŸè·å–
        if 'ç¾å›¢ä¸€çº§åˆ†ç±»çˆ†å“skuæ•°' in df.columns:
            value = df['ç¾å›¢ä¸€çº§åˆ†ç±»çˆ†å“skuæ•°'].iloc[0]
            self.assertEqual(value, 10, "åº”è¯¥è·å–åˆ°ç¬¬ä¸€è¡Œçš„å€¼")
        
        # æµ‹è¯•é»˜è®¤å€¼å¤„ç†
        default_value = 999
        value = df.get('ä¸å­˜åœ¨çš„åˆ—', pd.Series([default_value])).iloc[0]
        self.assertEqual(value, default_value, "æ‰¾ä¸åˆ°åˆ—åº”è¿”å›é»˜è®¤å€¼")


class TestDataIntegrity(unittest.TestCase):
    """æµ‹è¯•æ•°æ®å®Œæ•´æ€§"""
    
    def test_data_type_consistency(self):
        """æµ‹è¯•æ•°æ®ç±»å‹ä¸€è‡´æ€§"""
        # æµ‹è¯•æ•°å€¼ç±»å‹è½¬æ¢
        test_values = ['100', 100, 100.0, np.int64(100)]
        for val in test_values:
            numeric_val = pd.to_numeric(val, errors='coerce')
            self.assertEqual(numeric_val, 100, f"å€¼ {val} åº”è¯¥è½¬æ¢ä¸º100")
        
        # æµ‹è¯•æ— æ•ˆå€¼å¤„ç†
        invalid_val = pd.to_numeric('invalid', errors='coerce')
        self.assertTrue(pd.isna(invalid_val), "æ— æ•ˆå€¼åº”è½¬æ¢ä¸ºNaN")
    
    def test_dataframe_operations(self):
        """æµ‹è¯•DataFrameæ“ä½œçš„æ­£ç¡®æ€§"""
        df = pd.DataFrame({
            'A': [1, 2, 3, 4, 5],
            'B': [10, 20, 30, 40, 50]
        })
        
        # æµ‹è¯•numpyæ•°ç»„æå–
        arr_a = df['A'].values
        self.assertIsInstance(arr_a, np.ndarray, "åº”è¯¥è¿”å›numpyæ•°ç»„")
        self.assertEqual(len(arr_a), 5, "æ•°ç»„é•¿åº¦åº”è¯¥æ­£ç¡®")
        
        # æµ‹è¯•å‘é‡åŒ–è®¡ç®—
        result = arr_a * 2
        expected = np.array([2, 4, 6, 8, 10])
        np.testing.assert_array_equal(result, expected, "å‘é‡åŒ–è®¡ç®—åº”è¯¥æ­£ç¡®")


class TestErrorHandling(unittest.TestCase):
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    
    def test_missing_file_handling(self):
        """æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨çš„å¤„ç†"""
        # DataLoaderä¼šæ•è·å¼‚å¸¸å¹¶è®°å½•æ—¥å¿—ï¼Œä¸ä¼šæŠ›å‡ºå¼‚å¸¸
        # æ‰€ä»¥æˆ‘ä»¬æµ‹è¯•dataæ˜¯å¦ä¸ºç©º
        loader = DataLoader("ä¸å­˜åœ¨çš„æ–‡ä»¶.xlsx", use_cache=False)
        self.assertTrue(loader.data['kpi'].empty, "ä¸å­˜åœ¨çš„æ–‡ä»¶åº”è¯¥è¿”å›ç©ºæ•°æ®")
    
    def test_invalid_data_handling(self):
        """æµ‹è¯•æ— æ•ˆæ•°æ®å¤„ç†"""
        # æµ‹è¯•ç©ºDataFrame
        empty_df = pd.DataFrame()
        insights = DashboardComponents.generate_multispec_insights(empty_df)
        self.assertEqual(len(insights), 0, "ç©ºæ•°æ®åº”è¿”å›ç©ºåˆ—è¡¨")
        
        # æµ‹è¯•åŒ…å«NaNçš„æ•°æ®
        df_with_nan = pd.DataFrame({
            'åˆ†ç±»': ['A', 'B'],
            'æ€»SKUæ•°': [100, np.nan],
            'å¤šè§„æ ¼SKUæ•°': [50, 25]
        })
        
        # åº”è¯¥ä¸æŠ›å‡ºå¼‚å¸¸
        try:
            insights = DashboardComponents.generate_multispec_insights(df_with_nan)
            self.assertIsInstance(insights, list)
        except Exception as e:
            self.fail(f"ä¸åº”è¯¥æŠ›å‡ºå¼‚å¸¸: {e}")


def run_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # æ·»åŠ æ‰€æœ‰æµ‹è¯•ç±»
    suite.addTests(loader.loadTestsFromTestCase(TestDataCache))
    suite.addTests(loader.loadTestsFromTestCase(TestKPICalculation))
    suite.addTests(loader.loadTestsFromTestCase(TestMultispecRecognition))
    suite.addTests(loader.loadTestsFromTestCase(TestDataLoaderColumnMapping))
    suite.addTests(loader.loadTestsFromTestCase(TestDataIntegrity))
    suite.addTests(loader.loadTestsFromTestCase(TestErrorHandling))
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # æ‰“å°æ€»ç»“
    print("\n" + "="*70)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("="*70)
    print(f"âœ… è¿è¡Œæµ‹è¯•: {result.testsRun}ä¸ª")
    print(f"âœ… æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}ä¸ª")
    print(f"âŒ å¤±è´¥: {len(result.failures)}ä¸ª")
    print(f"ğŸ’¥ é”™è¯¯: {len(result.errors)}ä¸ª")
    
    if result.wasSuccessful():
        print("\nğŸ‰ æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ“ˆ æµ‹è¯•è¦†ç›–èŒƒå›´:")
        print("   âœ… æ•°æ®ç¼“å­˜æœºåˆ¶")
        print("   âœ… KPIè®¡ç®—é€»è¾‘")
        print("   âœ… å¤šè§„æ ¼è¯†åˆ«ç®—æ³•")
        print("   âœ… åˆ—åæ˜ å°„åŠŸèƒ½")
        print("   âœ… æ•°æ®å®Œæ•´æ€§")
        print("   âœ… é”™è¯¯å¤„ç†")
        return 0
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥")
        return 1


if __name__ == '__main__':
    import sys
    sys.exit(run_tests())
